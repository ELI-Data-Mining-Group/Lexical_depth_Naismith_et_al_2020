{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1_COCA dataset\n",
    "\n",
    "\n",
    "## Building the COCA dataset of 'key' word families\n",
    "\n",
    "Key family characteristics:\n",
    "- Frequency information based on COCA 100k list, available at https://www.wordfrequency.info/100k.asp\n",
    "- Mid-frequency lemmas, i.e., in the K3-K9 frequency bands\n",
    "- Word families with 4+ mid-frequency derivations and at least one derivation in each major word class (noun, verb, adjective, adverb)\n",
    "\n",
    "#### Sections of the notebook\n",
    "- [Initial setup](#Initial-setup)\n",
    "- [Preparing COCA dataframe](#Preparing-COCA-dataframe)\n",
    "- [POS tags](#POS-tags)\n",
    "- [Lemma information](#Lemma-information)\n",
    "- [Mid-frequency items](#Mid-frequency-items)\n",
    "- [Word families](#Word-families)\n",
    "- [Checking derivations](#Checking-derivations)\n",
    "- [Dataset narrowing](#Dataset-narrowing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import pickle as pkl\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Set preferred notebook format\n",
    "%pprint # turn off pretty printing\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing COCA dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>w1</th>\n",
       "      <th>L1</th>\n",
       "      <th>c1</th>\n",
       "      <th>pc</th>\n",
       "      <th>spelling</th>\n",
       "      <th>coca</th>\n",
       "      <th>pcoca</th>\n",
       "      <th>pbnc</th>\n",
       "      <th>psoap</th>\n",
       "      <th>ph3</th>\n",
       "      <th>ph2</th>\n",
       "      <th>ph1</th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pb1</th>\n",
       "      <th>pb2</th>\n",
       "      <th>pb3</th>\n",
       "      <th>pb4</th>\n",
       "      <th>pb5</th>\n",
       "      <th>pb6</th>\n",
       "      <th>pb7</th>\n",
       "      <th>tpcoca</th>\n",
       "      <th>tpbnc</th>\n",
       "      <th>tpsoap</th>\n",
       "      <th>tph3</th>\n",
       "      <th>tph2</th>\n",
       "      <th>tph1</th>\n",
       "      <th>tpc1</th>\n",
       "      <th>tpc2</th>\n",
       "      <th>tpc3</th>\n",
       "      <th>tpc4</th>\n",
       "      <th>tpc5</th>\n",
       "      <th>tpb1</th>\n",
       "      <th>tpb2</th>\n",
       "      <th>tpb3</th>\n",
       "      <th>tpb4</th>\n",
       "      <th>tpb5</th>\n",
       "      <th>tpb6</th>\n",
       "      <th>tpb7</th>\n",
       "      <th>bnc</th>\n",
       "      <th>fs</th>\n",
       "      <th>fh3</th>\n",
       "      <th>fh2</th>\n",
       "      <th>fh1</th>\n",
       "      <th>fc1</th>\n",
       "      <th>fc2</th>\n",
       "      <th>fc3</th>\n",
       "      <th>fc4</th>\n",
       "      <th>fc5</th>\n",
       "      <th>fb1</th>\n",
       "      <th>fb2</th>\n",
       "      <th>fb3</th>\n",
       "      <th>fb4</th>\n",
       "      <th>fb5</th>\n",
       "      <th>fb6</th>\n",
       "      <th>fb7</th>\n",
       "      <th>tcoca</th>\n",
       "      <th>tbnc</th>\n",
       "      <th>tsoap</th>\n",
       "      <th>th3</th>\n",
       "      <th>th2</th>\n",
       "      <th>th1</th>\n",
       "      <th>tc1</th>\n",
       "      <th>tc2</th>\n",
       "      <th>tc3</th>\n",
       "      <th>tc4</th>\n",
       "      <th>tc5</th>\n",
       "      <th>tb1</th>\n",
       "      <th>tb2</th>\n",
       "      <th>tb3</th>\n",
       "      <th>tb4</th>\n",
       "      <th>tb5</th>\n",
       "      <th>tb6</th>\n",
       "      <th>tb7</th>\n",
       "      <th>Unnamed: 78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>at</td>\n",
       "      <td>0.11</td>\n",
       "      <td></td>\n",
       "      <td>25131726</td>\n",
       "      <td>54124.71</td>\n",
       "      <td>59717.97</td>\n",
       "      <td>21403.42</td>\n",
       "      <td>59363.87</td>\n",
       "      <td>63479.96</td>\n",
       "      <td>65266.92</td>\n",
       "      <td>46393.26</td>\n",
       "      <td>53301.68</td>\n",
       "      <td>53775.83</td>\n",
       "      <td>53613.78</td>\n",
       "      <td>63981.74</td>\n",
       "      <td>41050.47</td>\n",
       "      <td>52467.51</td>\n",
       "      <td>58832.77</td>\n",
       "      <td>60670.30</td>\n",
       "      <td>68926.84</td>\n",
       "      <td>73581.36</td>\n",
       "      <td>67229.24</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5971797</td>\n",
       "      <td>2140342</td>\n",
       "      <td>5797074</td>\n",
       "      <td>7579669</td>\n",
       "      <td>8545851</td>\n",
       "      <td>4433575</td>\n",
       "      <td>4820039</td>\n",
       "      <td>5138750</td>\n",
       "      <td>4917319</td>\n",
       "      <td>5826573</td>\n",
       "      <td>409013</td>\n",
       "      <td>834722</td>\n",
       "      <td>427243</td>\n",
       "      <td>635001</td>\n",
       "      <td>1136961</td>\n",
       "      <td>1128125</td>\n",
       "      <td>1400732</td>\n",
       "      <td>188643</td>\n",
       "      <td>4045</td>\n",
       "      <td>21985</td>\n",
       "      <td>42556</td>\n",
       "      <td>39575</td>\n",
       "      <td>10875</td>\n",
       "      <td>38159</td>\n",
       "      <td>19219</td>\n",
       "      <td>53139</td>\n",
       "      <td>56903</td>\n",
       "      <td>21223</td>\n",
       "      <td>904</td>\n",
       "      <td>463</td>\n",
       "      <td>210</td>\n",
       "      <td>518</td>\n",
       "      <td>533</td>\n",
       "      <td>501</td>\n",
       "      <td>916</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>cc</td>\n",
       "      <td>0.08</td>\n",
       "      <td></td>\n",
       "      <td>12368293</td>\n",
       "      <td>26636.86</td>\n",
       "      <td>25808.34</td>\n",
       "      <td>17677.41</td>\n",
       "      <td>26260.07</td>\n",
       "      <td>28577.44</td>\n",
       "      <td>33417.48</td>\n",
       "      <td>26089.72</td>\n",
       "      <td>25756.04</td>\n",
       "      <td>26458.18</td>\n",
       "      <td>24577.22</td>\n",
       "      <td>30346.60</td>\n",
       "      <td>26107.37</td>\n",
       "      <td>26803.23</td>\n",
       "      <td>26337.68</td>\n",
       "      <td>22236.16</td>\n",
       "      <td>27659.40</td>\n",
       "      <td>26888.33</td>\n",
       "      <td>28883.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2580834</td>\n",
       "      <td>1767741</td>\n",
       "      <td>2564381</td>\n",
       "      <td>3412219</td>\n",
       "      <td>4375583</td>\n",
       "      <td>2493266</td>\n",
       "      <td>2329103</td>\n",
       "      <td>2528310</td>\n",
       "      <td>2254160</td>\n",
       "      <td>2763549</td>\n",
       "      <td>260125</td>\n",
       "      <td>426421</td>\n",
       "      <td>191264</td>\n",
       "      <td>232733</td>\n",
       "      <td>456247</td>\n",
       "      <td>412243</td>\n",
       "      <td>601801</td>\n",
       "      <td>188462</td>\n",
       "      <td>4045</td>\n",
       "      <td>21985</td>\n",
       "      <td>42264</td>\n",
       "      <td>38849</td>\n",
       "      <td>10873</td>\n",
       "      <td>38146</td>\n",
       "      <td>19153</td>\n",
       "      <td>53129</td>\n",
       "      <td>56812</td>\n",
       "      <td>21222</td>\n",
       "      <td>904</td>\n",
       "      <td>463</td>\n",
       "      <td>210</td>\n",
       "      <td>518</td>\n",
       "      <td>533</td>\n",
       "      <td>501</td>\n",
       "      <td>916</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ii</td>\n",
       "      <td>0.01</td>\n",
       "      <td></td>\n",
       "      <td>11971724</td>\n",
       "      <td>25782.79</td>\n",
       "      <td>30086.53</td>\n",
       "      <td>10067.32</td>\n",
       "      <td>27505.53</td>\n",
       "      <td>32184.17</td>\n",
       "      <td>37182.86</td>\n",
       "      <td>21502.94</td>\n",
       "      <td>19640.22</td>\n",
       "      <td>25872.17</td>\n",
       "      <td>23814.03</td>\n",
       "      <td>38260.97</td>\n",
       "      <td>17505.61</td>\n",
       "      <td>21465.10</td>\n",
       "      <td>26809.46</td>\n",
       "      <td>25441.17</td>\n",
       "      <td>37980.66</td>\n",
       "      <td>45030.26</td>\n",
       "      <td>34311.38</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3008653</td>\n",
       "      <td>1006732</td>\n",
       "      <td>2686004</td>\n",
       "      <td>3842872</td>\n",
       "      <td>4868611</td>\n",
       "      <td>2054930</td>\n",
       "      <td>1776053</td>\n",
       "      <td>2472312</td>\n",
       "      <td>2184162</td>\n",
       "      <td>3484281</td>\n",
       "      <td>174420</td>\n",
       "      <td>341495</td>\n",
       "      <td>194690</td>\n",
       "      <td>266278</td>\n",
       "      <td>626498</td>\n",
       "      <td>690389</td>\n",
       "      <td>714883</td>\n",
       "      <td>188408</td>\n",
       "      <td>4035</td>\n",
       "      <td>21985</td>\n",
       "      <td>42470</td>\n",
       "      <td>39429</td>\n",
       "      <td>10870</td>\n",
       "      <td>38144</td>\n",
       "      <td>19106</td>\n",
       "      <td>53114</td>\n",
       "      <td>56823</td>\n",
       "      <td>21221</td>\n",
       "      <td>894</td>\n",
       "      <td>463</td>\n",
       "      <td>210</td>\n",
       "      <td>518</td>\n",
       "      <td>533</td>\n",
       "      <td>501</td>\n",
       "      <td>916</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>at</td>\n",
       "      <td>0.06</td>\n",
       "      <td></td>\n",
       "      <td>10327063</td>\n",
       "      <td>22240.78</td>\n",
       "      <td>20853.49</td>\n",
       "      <td>15632.54</td>\n",
       "      <td>22557.53</td>\n",
       "      <td>21357.82</td>\n",
       "      <td>20346.25</td>\n",
       "      <td>21403.59</td>\n",
       "      <td>22960.81</td>\n",
       "      <td>24395.42</td>\n",
       "      <td>23734.44</td>\n",
       "      <td>18637.48</td>\n",
       "      <td>19811.69</td>\n",
       "      <td>22470.99</td>\n",
       "      <td>23270.21</td>\n",
       "      <td>23642.27</td>\n",
       "      <td>20335.03</td>\n",
       "      <td>20755.41</td>\n",
       "      <td>22095.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2085349</td>\n",
       "      <td>1563254</td>\n",
       "      <td>2202816</td>\n",
       "      <td>2550178</td>\n",
       "      <td>2664076</td>\n",
       "      <td>2045436</td>\n",
       "      <td>2076332</td>\n",
       "      <td>2331195</td>\n",
       "      <td>2176862</td>\n",
       "      <td>1697244</td>\n",
       "      <td>197397</td>\n",
       "      <td>357498</td>\n",
       "      <td>168988</td>\n",
       "      <td>247450</td>\n",
       "      <td>335430</td>\n",
       "      <td>318215</td>\n",
       "      <td>460371</td>\n",
       "      <td>188277</td>\n",
       "      <td>4042</td>\n",
       "      <td>21985</td>\n",
       "      <td>42289</td>\n",
       "      <td>39059</td>\n",
       "      <td>10847</td>\n",
       "      <td>38138</td>\n",
       "      <td>19121</td>\n",
       "      <td>53117</td>\n",
       "      <td>56680</td>\n",
       "      <td>21221</td>\n",
       "      <td>903</td>\n",
       "      <td>463</td>\n",
       "      <td>210</td>\n",
       "      <td>517</td>\n",
       "      <td>533</td>\n",
       "      <td>501</td>\n",
       "      <td>915</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ii</td>\n",
       "      <td>0.09</td>\n",
       "      <td></td>\n",
       "      <td>8035789</td>\n",
       "      <td>17306.20</td>\n",
       "      <td>18307.46</td>\n",
       "      <td>6702.35</td>\n",
       "      <td>17055.21</td>\n",
       "      <td>17335.58</td>\n",
       "      <td>17775.94</td>\n",
       "      <td>15433.91</td>\n",
       "      <td>13194.97</td>\n",
       "      <td>17503.23</td>\n",
       "      <td>18490.76</td>\n",
       "      <td>21952.50</td>\n",
       "      <td>12382.49</td>\n",
       "      <td>13318.05</td>\n",
       "      <td>16743.76</td>\n",
       "      <td>19122.49</td>\n",
       "      <td>21928.16</td>\n",
       "      <td>24739.06</td>\n",
       "      <td>20770.32</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1830746</td>\n",
       "      <td>670235</td>\n",
       "      <td>1665496</td>\n",
       "      <td>2069913</td>\n",
       "      <td>2327528</td>\n",
       "      <td>1474943</td>\n",
       "      <td>1193213</td>\n",
       "      <td>1672586</td>\n",
       "      <td>1695925</td>\n",
       "      <td>1999131</td>\n",
       "      <td>123375</td>\n",
       "      <td>211881</td>\n",
       "      <td>121593</td>\n",
       "      <td>200144</td>\n",
       "      <td>361709</td>\n",
       "      <td>379291</td>\n",
       "      <td>432753</td>\n",
       "      <td>188167</td>\n",
       "      <td>4035</td>\n",
       "      <td>21985</td>\n",
       "      <td>42242</td>\n",
       "      <td>38991</td>\n",
       "      <td>10863</td>\n",
       "      <td>38126</td>\n",
       "      <td>19043</td>\n",
       "      <td>53041</td>\n",
       "      <td>56740</td>\n",
       "      <td>21217</td>\n",
       "      <td>895</td>\n",
       "      <td>463</td>\n",
       "      <td>210</td>\n",
       "      <td>518</td>\n",
       "      <td>533</td>\n",
       "      <td>501</td>\n",
       "      <td>915</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   w1   L1  c1    pc spelling      coca     pcoca      pbnc     psoap  \\\n",
       "0   1  the  the  at  0.11           25131726  54124.71  59717.97  21403.42   \n",
       "1   2  and  and  cc  0.08           12368293  26636.86  25808.34  17677.41   \n",
       "2   3   of   of  ii  0.01           11971724  25782.79  30086.53  10067.32   \n",
       "3   4    a    a  at  0.06           10327063  22240.78  20853.49  15632.54   \n",
       "4   5   in   in  ii  0.09            8035789  17306.20  18307.46   6702.35   \n",
       "\n",
       "        ph3       ph2       ph1       pc1       pc2       pc3       pc4  \\\n",
       "0  59363.87  63479.96  65266.92  46393.26  53301.68  53775.83  53613.78   \n",
       "1  26260.07  28577.44  33417.48  26089.72  25756.04  26458.18  24577.22   \n",
       "2  27505.53  32184.17  37182.86  21502.94  19640.22  25872.17  23814.03   \n",
       "3  22557.53  21357.82  20346.25  21403.59  22960.81  24395.42  23734.44   \n",
       "4  17055.21  17335.58  17775.94  15433.91  13194.97  17503.23  18490.76   \n",
       "\n",
       "        pc5       pb1       pb2       pb3       pb4       pb5       pb6  \\\n",
       "0  63981.74  41050.47  52467.51  58832.77  60670.30  68926.84  73581.36   \n",
       "1  30346.60  26107.37  26803.23  26337.68  22236.16  27659.40  26888.33   \n",
       "2  38260.97  17505.61  21465.10  26809.46  25441.17  37980.66  45030.26   \n",
       "3  18637.48  19811.69  22470.99  23270.21  23642.27  20335.03  20755.41   \n",
       "4  21952.50  12382.49  13318.05  16743.76  19122.49  21928.16  24739.06   \n",
       "\n",
       "        pb7  tpcoca  tpbnc  tpsoap  tph3  tph2  tph1  tpc1  tpc2  tpc3  tpc4  \\\n",
       "0  67229.24    1.00    1.0     1.0  1.00  1.00   1.0  1.00  1.00   1.0  1.00   \n",
       "1  28883.92    1.00    1.0     1.0  0.99  0.98   1.0  1.00  1.00   1.0  0.99   \n",
       "2  34311.38    1.00    1.0     1.0  1.00  1.00   1.0  1.00  0.99   1.0  0.99   \n",
       "3  22095.87    1.00    1.0     1.0  0.99  0.99   1.0  1.00  0.99   1.0  0.99   \n",
       "4  20770.32    0.99    1.0     1.0  0.99  0.98   1.0  0.99  0.99   1.0  0.99   \n",
       "\n",
       "   tpc5  tpb1  tpb2  tpb3  tpb4  tpb5  tpb6  tpb7      bnc       fs      fh3  \\\n",
       "0   1.0  1.00   1.0   1.0   1.0   1.0   1.0   1.0  5971797  2140342  5797074   \n",
       "1   1.0  1.00   1.0   1.0   1.0   1.0   1.0   1.0  2580834  1767741  2564381   \n",
       "2   1.0  0.99   1.0   1.0   1.0   1.0   1.0   1.0  3008653  1006732  2686004   \n",
       "3   1.0  1.00   1.0   1.0   1.0   1.0   1.0   1.0  2085349  1563254  2202816   \n",
       "4   1.0  0.99   1.0   1.0   1.0   1.0   1.0   1.0  1830746   670235  1665496   \n",
       "\n",
       "       fh2      fh1      fc1      fc2      fc3      fc4      fc5     fb1  \\\n",
       "0  7579669  8545851  4433575  4820039  5138750  4917319  5826573  409013   \n",
       "1  3412219  4375583  2493266  2329103  2528310  2254160  2763549  260125   \n",
       "2  3842872  4868611  2054930  1776053  2472312  2184162  3484281  174420   \n",
       "3  2550178  2664076  2045436  2076332  2331195  2176862  1697244  197397   \n",
       "4  2069913  2327528  1474943  1193213  1672586  1695925  1999131  123375   \n",
       "\n",
       "      fb2     fb3     fb4      fb5      fb6      fb7   tcoca  tbnc  tsoap  \\\n",
       "0  834722  427243  635001  1136961  1128125  1400732  188643  4045  21985   \n",
       "1  426421  191264  232733   456247   412243   601801  188462  4045  21985   \n",
       "2  341495  194690  266278   626498   690389   714883  188408  4035  21985   \n",
       "3  357498  168988  247450   335430   318215   460371  188277  4042  21985   \n",
       "4  211881  121593  200144   361709   379291   432753  188167  4035  21985   \n",
       "\n",
       "     th3    th2    th1    tc1    tc2    tc3    tc4    tc5  tb1  tb2  tb3  tb4  \\\n",
       "0  42556  39575  10875  38159  19219  53139  56903  21223  904  463  210  518   \n",
       "1  42264  38849  10873  38146  19153  53129  56812  21222  904  463  210  518   \n",
       "2  42470  39429  10870  38144  19106  53114  56823  21221  894  463  210  518   \n",
       "3  42289  39059  10847  38138  19121  53117  56680  21221  903  463  210  517   \n",
       "4  42242  38991  10863  38126  19043  53041  56740  21217  895  463  210  518   \n",
       "\n",
       "   tb5  tb6  tb7 Unnamed: 78  \n",
       "0  533  501  916              \n",
       "1  533  501  916              \n",
       "2  533  501  916              \n",
       "3  533  501  915              \n",
       "4  533  501  915              "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in necessary file\n",
    "coca = pd.read_csv('COCA_frequency_info.txt', skiprows=2, encoding=\"utf8\", sep='\\t', na_filter=False)\n",
    "coca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTANT NOTE: The frequency information is a licensed dataset and is not publicly available. As such, this notebook will not run unless the dataset has been purchased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrow down to only the relevant columns\n",
    "coca_df = coca[['ID', 'w1', 'L1', 'c1', 'coca','fc1']]\n",
    "\n",
    "# Rename columns\n",
    "coca_df.columns = ['rank', 'word', 'lemma', 'POS', 'freq','spoken_freq']\n",
    "\n",
    "# Set rank as index\n",
    "coca_df = coca_df.set_index('rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating column of written data (total freq - spoken freq)\n",
    "coca_df['written_freq'] = coca_df.freq - coca_df.spoken_freq\n",
    "\n",
    "# And then dropping freq and spoken_freq columns as they are no longer needed\n",
    "coca_df = coca_df.drop(['freq','spoken_freq'], axis=1)\n",
    "\n",
    "# And simpliying 'written_freq' column name to just 'word_freq' - from here on, all 'freq' references \n",
    "#are to the written texts only.\n",
    "coca_df.columns = ['word', 'lemma', 'POS', 'word_freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-rank according to written_freq\n",
    "coca_df = coca_df.sort_values(by=['word_freq'],ascending=False)\n",
    "coca_df = coca_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>word_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2319</td>\n",
       "      <td>self</td>\n",
       "      <td>self</td>\n",
       "      <td>nn1</td>\n",
       "      <td>15731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100813</td>\n",
       "      <td>self</td>\n",
       "      <td>self</td>\n",
       "      <td>jj</td>\n",
       "      <td>-264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word lemma  POS  word_freq\n",
       "2319    self  self  nn1      15731\n",
       "100813  self  self   jj       -264"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The last item has total freq of 112 and spoken freq of 376 - This appears to be a glitch in the COCA spreadsheet\n",
    "coca_df.loc[coca_df.word == 'self']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>word_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>at</td>\n",
       "      <td>20698151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ii</td>\n",
       "      <td>9916794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>cc</td>\n",
       "      <td>9875027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>at</td>\n",
       "      <td>8281627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ii</td>\n",
       "      <td>6560846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word lemma POS  word_freq\n",
       "0  the   the  at   20698151\n",
       "1   of    of  ii    9916794\n",
       "2  and   and  cc    9875027\n",
       "3    a     a  at    8281627\n",
       "4   in    in  ii    6560846"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coca_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS tags\n",
    "\n",
    "The tagset used in the expert-speaker corpus (COCA) and the learner corpus (PELIC) are tagged using the different tagsets. COCA uses the [CLAWS 7 tagset](http://ucrel.lancs.ac.uk/claws7tags.html) whereas PELIC uses NLTK's tagger which uses the [Penn Treebank tagset](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html).  \n",
    "To address this issue and to simplify mapping, a simplified version of the CLAWS 7 tagset will be used, collating groups where appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jj       29604\n",
       "nn1      27154\n",
       "nn2      15906\n",
       "vv0       5219\n",
       "vvd       5093\n",
       "vvn       4873\n",
       "vvg       4593\n",
       "vvz       3547\n",
       "rr        3152\n",
       "jjr        365\n",
       "jjt        304\n",
       "mc         237\n",
       "uh         170\n",
       "ii         146\n",
       "md          93\n",
       "cs          56\n",
       "pp          54\n",
       "mf          52\n",
       "pn          34\n",
       "rrr         25\n",
       "dd          22\n",
       "da          17\n",
       "rrt         17\n",
       "vm          15\n",
       "appge       13\n",
       "cc           7\n",
       "at           5\n",
       "to           4\n",
       "vh0          3\n",
       "db           3\n",
       "vhz          2\n",
       "ge           2\n",
       "vdg          2\n",
       "vbr          2\n",
       "vdz          2\n",
       "vmk          2\n",
       "xx           2\n",
       "vbn          1\n",
       "vbdz         1\n",
       "vhd          1\n",
       "vhn          1\n",
       "vhg          1\n",
       "vbz          1\n",
       "vvgk         1\n",
       "vbm          1\n",
       "vv           1\n",
       "vdd          1\n",
       "ex           1\n",
       "vbdr         1\n",
       "vb0          1\n",
       "vdn          1\n",
       "vbg          1\n",
       "at1          1\n",
       "vd0          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS Used in COCA: List of all possible COCA POS tags\n",
    "coca_df['POS'].apply(pd.Series).stack().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify the POS column by keeping only the first two letters, \n",
    "# e.g. so that different types of nouns will all be 'nn'.\n",
    "coca_df['POS'] = [x[0:2] for x in coca_df.POS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further simplifying by combining types of verbs and a POS mapping dictionary\n",
    "coca_pos_map_dict = {'nn': 'nn', 'jj': 'jj', 'vv': 'vv', 'rr': 'rr',\n",
    "                     'mc': 'mc', 'uh': 'uh', 'ii': 'ii', 'md': 'md',\n",
    "                     'cs': 'cs', 'pp': 'pp', 'mf': 'mf', 'pn': 'pn',\n",
    "                     'dd': 'dd', 'da': 'da', 'vm': 'vv', 'ap': 'ap',\n",
    "                     'vb': 'vv', 'vh': 'vv','cc': 'cc', 'vd': 'vv',\n",
    "                     'at': 'at', 'to': 'to', 'db':'db', 'xx': 'xx',\n",
    "                     'ge': 'ge', 'ex': 'ex'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping that dictionary to the new simple_POS column\n",
    "coca_df.POS = coca_df.POS.map(coca_pos_map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn    43060\n",
       "jj    30273\n",
       "vv    23368\n",
       "rr     3194\n",
       "mc      237\n",
       "uh      170\n",
       "ii      146\n",
       "md       93\n",
       "cs       56\n",
       "pp       54\n",
       "mf       52\n",
       "pn       34\n",
       "dd       22\n",
       "da       17\n",
       "ap       13\n",
       "cc        7\n",
       "at        6\n",
       "to        4\n",
       "db        3\n",
       "ge        2\n",
       "xx        2\n",
       "ex        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking resulting simple_POS\n",
    "coca_df['POS'].apply(pd.Series).stack().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding word_POS and lemma_POS columns\n",
    "coca_df['word_POS'] = list(zip(coca_df.word, coca_df.POS))\n",
    "coca_df['lemma_POS'] = list(zip(coca_df.lemma, coca_df.POS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>word_freq</th>\n",
       "      <th>word_POS</th>\n",
       "      <th>lemma_POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>at</td>\n",
       "      <td>20698151</td>\n",
       "      <td>(the, at)</td>\n",
       "      <td>(the, at)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ii</td>\n",
       "      <td>9916794</td>\n",
       "      <td>(of, ii)</td>\n",
       "      <td>(of, ii)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>cc</td>\n",
       "      <td>9875027</td>\n",
       "      <td>(and, cc)</td>\n",
       "      <td>(and, cc)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>at</td>\n",
       "      <td>8281627</td>\n",
       "      <td>(a, at)</td>\n",
       "      <td>(a, at)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ii</td>\n",
       "      <td>6560846</td>\n",
       "      <td>(in, ii)</td>\n",
       "      <td>(in, ii)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word lemma POS  word_freq   word_POS  lemma_POS\n",
       "0  the   the  at   20698151  (the, at)  (the, at)\n",
       "1   of    of  ii    9916794   (of, ii)   (of, ii)\n",
       "2  and   and  cc    9875027  (and, cc)  (and, cc)\n",
       "3    a     a  at    8281627    (a, at)    (a, at)\n",
       "4   in    in  ii    6560846   (in, ii)   (in, ii)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coca_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: Lemmas rather than words are the principle countining unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lemma  POS\n",
       "the    at     20698151\n",
       "be     vv     10782841\n",
       "of     ii      9916794\n",
       "and    cc      9875027\n",
       "a      at      9523432\n",
       "Name: word_freq, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "lemma          POS\n",
       "hand-off       jj       2\n",
       "newsdesk       nn       1\n",
       "uncapitalized  jj       1\n",
       "puzzlemaster   nn       0\n",
       "self           jj    -264\n",
       "Name: word_freq, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grouping the lemmas by their raw frequencies, summing the same lemmas and sorting in descending order\n",
    "lemma_freq = coca_df.groupby(['lemma', 'POS'])['word_freq'].sum().sort_values(ascending=False)\n",
    "lemma_freq[0:5]\n",
    "lemma_freq[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('trouper', 'nn'), 72), (('minestrone', 'nn'), 103), (('lebensraum', 'nn'), 22), (('export-driven', 'jj'), 24), (('insect-eating', 'jj'), 19)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dictionary of the (lemma, POS) tuples and their lemma frequencies\n",
    "lemma_dict = lemma_freq.to_dict()\n",
    "random.sample(lemma_dict.items(),5) # Random sample of the dictionary to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Pickling the lemma dict for future use and checking that it loads correctly\n",
    "a = lemma_dict\n",
    "\n",
    "with open('lemma_dict.pkl', 'wb') as handle:\n",
    "    pkl.dump(a, handle, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('lemma_dict.pkl', 'rb') as handle:\n",
    "    b = pkl.load(handle)\n",
    "\n",
    "print(a == b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding lemma_POS and lemma_freq column based on the above\n",
    "coca_df['lemma_POS'] = coca_df.apply(lambda row: row.lemma + ' ' + row.POS, axis=1)\n",
    "coca_df['lemma_POS'] = [tuple(x.split()) for x in coca_df['lemma_POS']]\n",
    "coca_df['lemma_freq'] = coca_df.lemma_POS.map(lemma_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And a word_POS column too for later use\n",
    "coca_df['word_POS'] = coca_df.apply(lambda row: row.word + ' ' + row.POS, axis=1)\n",
    "coca_df['word_POS'] = [tuple(x.split()) for x in coca_df['word_POS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "coca_df = coca_df[['word','POS','word_freq','word_POS','lemma','lemma_POS','lemma_freq']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "      <th>word_freq</th>\n",
       "      <th>word_POS</th>\n",
       "      <th>lemma</th>\n",
       "      <th>lemma_POS</th>\n",
       "      <th>lemma_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>at</td>\n",
       "      <td>20698151</td>\n",
       "      <td>(the, at)</td>\n",
       "      <td>the</td>\n",
       "      <td>(the, at)</td>\n",
       "      <td>20698151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>ii</td>\n",
       "      <td>9916794</td>\n",
       "      <td>(of, ii)</td>\n",
       "      <td>of</td>\n",
       "      <td>(of, ii)</td>\n",
       "      <td>9916794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "      <td>cc</td>\n",
       "      <td>9875027</td>\n",
       "      <td>(and, cc)</td>\n",
       "      <td>and</td>\n",
       "      <td>(and, cc)</td>\n",
       "      <td>9875027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>at</td>\n",
       "      <td>8281627</td>\n",
       "      <td>(a, at)</td>\n",
       "      <td>a</td>\n",
       "      <td>(a, at)</td>\n",
       "      <td>9523432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>in</td>\n",
       "      <td>ii</td>\n",
       "      <td>6560846</td>\n",
       "      <td>(in, ii)</td>\n",
       "      <td>in</td>\n",
       "      <td>(in, ii)</td>\n",
       "      <td>6560846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word POS  word_freq   word_POS lemma  lemma_POS  lemma_freq\n",
       "0  the  at   20698151  (the, at)   the  (the, at)    20698151\n",
       "1   of  ii    9916794   (of, ii)    of   (of, ii)     9916794\n",
       "2  and  cc    9875027  (and, cc)   and  (and, cc)     9875027\n",
       "3    a  at    8281627    (a, at)     a    (a, at)     9523432\n",
       "4   in  ii    6560846   (in, ii)    in   (in, ii)     6560846"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling dataframe for later use\n",
    "coca_df.to_pickle(\"coca_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mid-frequency items\n",
    "Narrowing the coca_df to only the items in the K3-K9 frequency bands, based on **lemma** frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>lemma_POS</th>\n",
       "      <th>lemma_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>(the, at)</td>\n",
       "      <td>20698151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>be</td>\n",
       "      <td>(be, vv)</td>\n",
       "      <td>10782841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>of</td>\n",
       "      <td>(of, ii)</td>\n",
       "      <td>9916794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>and</td>\n",
       "      <td>(and, cc)</td>\n",
       "      <td>9875027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>(a, at)</td>\n",
       "      <td>9523432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lemma  lemma_POS  lemma_freq\n",
       "0   the  (the, at)    20698151\n",
       "1    be   (be, vv)    10782841\n",
       "2    of   (of, ii)     9916794\n",
       "3   and  (and, cc)     9875027\n",
       "4     a    (a, at)     9523432"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid_freq = coca_df.sort_values(by=['lemma_freq'], ascending = False) # First, sort rows by lemma freq\n",
    "mid_freq.reset_index(inplace = True) #reset index since word rank not important\n",
    "mid_freq = mid_freq.drop(['index','word','word_POS','POS','word_freq'], axis =1) #remove word-related columns\n",
    "mid_freq = mid_freq.drop_duplicates(subset =\"lemma_POS\", keep='first') # Then, drop duplicates (1 row per lemma)\n",
    "mid_freq.reset_index(inplace = True, drop = True) #reset index again to fix numbering\n",
    "mid_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>lemma_POS</th>\n",
       "      <th>lemma_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2001</td>\n",
       "      <td>touch</td>\n",
       "      <td>(touch, nn)</td>\n",
       "      <td>18185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2002</td>\n",
       "      <td>scholar</td>\n",
       "      <td>(scholar, nn)</td>\n",
       "      <td>18184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2003</td>\n",
       "      <td>wonderful</td>\n",
       "      <td>(wonderful, jj)</td>\n",
       "      <td>18161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2004</td>\n",
       "      <td>ride</td>\n",
       "      <td>(ride, nn)</td>\n",
       "      <td>18154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2005</td>\n",
       "      <td>teaspoon</td>\n",
       "      <td>(teaspoon, nn)</td>\n",
       "      <td>18150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8996</td>\n",
       "      <td>diver</td>\n",
       "      <td>(diver, nn)</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8997</td>\n",
       "      <td>spill</td>\n",
       "      <td>(spill, nn)</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8998</td>\n",
       "      <td>insult</td>\n",
       "      <td>(insult, vv)</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8999</td>\n",
       "      <td>sole</td>\n",
       "      <td>(sole, nn)</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>rehearse</td>\n",
       "      <td>(rehearse, vv)</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lemma        lemma_POS  lemma_freq\n",
       "2001      touch      (touch, nn)       18185\n",
       "2002    scholar    (scholar, nn)       18184\n",
       "2003  wonderful  (wonderful, jj)       18161\n",
       "2004       ride       (ride, nn)       18154\n",
       "2005   teaspoon   (teaspoon, nn)       18150\n",
       "...         ...              ...         ...\n",
       "8996      diver      (diver, nn)        2016\n",
       "8997      spill      (spill, nn)        2016\n",
       "8998     insult     (insult, vv)        2015\n",
       "8999       sole       (sole, nn)        2015\n",
       "9000   rehearse   (rehearse, vv)        2014\n",
       "\n",
       "[7000 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Narrow to 2001-9000 items\n",
    "mid_freq = mid_freq.iloc[2001:9001,]\n",
    "len(mid_freq)\n",
    "mid_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out txt file of the lemmas to categorize into word families \n",
    "#pd.Series(mid_freq.lemma).to_csv('mid_freq_lemmas.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find which forms belong to each word family, the ['familizer' function](https://lextutor.ca/familizer/) at lextutor.ca is used, producing the following csv.  \n",
    "\n",
    "**NOTE:** It is necessary to check the above txt manually as there may be missing line breaks, in this case: _writewronged_ and _withdrewaccurate_. As such, the above line is hashed out - only use the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>abandon  abandoned abandoning abandonment aban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>able  abilities ability abler ablest ably inab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>abnormal  abnormalities abnormality abnormally</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>aboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>abolish  abolished abolishes abolishing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               forms\n",
       "0  abandon  abandoned abandoning abandonment aban...\n",
       "1  able  abilities ability abler ablest ably inab...\n",
       "2     abnormal  abnormalities abnormality abnormally\n",
       "3                                            aboard \n",
       "4            abolish  abolished abolishes abolishing"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the new txt file as a dataframe\n",
    "mid_freq_fams = pd.read_csv('mid_freq_families.txt', encoding = \"ISO-8859-1\", names=[\"forms\"])\n",
    "mid_freq_fams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forms</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[abandon, abandoned, abandoning, abandonment, ...</td>\n",
       "      <td>abandon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[able, abilities, ability, abler, ablest, ably...</td>\n",
       "      <td>able</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[abnormal, abnormalities, abnormality, abnorma...</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[aboard]</td>\n",
       "      <td>aboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[abolish, abolished, abolishes, abolishing]</td>\n",
       "      <td>abolish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               forms    family\n",
       "0  [abandon, abandoned, abandoning, abandonment, ...   abandon\n",
       "1  [able, abilities, ability, abler, ablest, ably...      able\n",
       "2  [abnormal, abnormalities, abnormality, abnorma...  abnormal\n",
       "3                                           [aboard]    aboard\n",
       "4        [abolish, abolished, abolishes, abolishing]   abolish"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean up above dataframe\n",
    "mid_freq_fams.forms = [x.split() for x in mid_freq_fams.forms] #make lemma families into lists\n",
    "mid_freq_fams['family'] = [x[0] for x in mid_freq_fams.forms] #create column with head lemma from COCA index\n",
    "mid_freq_fams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying function to make a new column with POS for all the forms in each lemma family\n",
    "# Need to use COCA 100k list look up to decide POS\n",
    "\n",
    "# Making COCA word:word_POS dict for the function to use\n",
    "coca_pos_dict = pd.Series(coca_df.word.values,coca_df.word_POS).to_dict()\n",
    "\n",
    "# And inverting this dict, combining the values of any duplicate keys, i.e. the homonyms\n",
    "inv_coca_pos_dict = {}\n",
    "for k, v in coca_pos_dict.items():\n",
    "    inv_coca_pos_dict[v] = inv_coca_pos_dict.get(v, [])\n",
    "    inv_coca_pos_dict[v].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the function looking up the word_POS given a word\n",
    "def find_COCA_POS_from_word(word_list):\n",
    "    word_and_POS_list = []\n",
    "    for word in word_list:\n",
    "        if word in inv_coca_pos_dict:\n",
    "            word_and_POS_list.append(inv_coca_pos_dict[word])\n",
    "    return word_and_POS_list\n",
    "\n",
    "# Applying the function to create a new column in the dataframe\n",
    "mid_freq_fams['form_POS'] = mid_freq_fams.forms.apply(find_COCA_POS_from_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening the above column\n",
    "mid_freq_fams['form_POS'] = mid_freq_fams['form_POS'].apply(lambda i:[x for y in i for x in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>forms</th>\n",
       "      <th>form_POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>abandon</td>\n",
       "      <td>[abandon, abandoned, abandoning, abandonment, ...</td>\n",
       "      <td>[(abandon, vv), (abandon, nn), (abandoned, vv)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>able</td>\n",
       "      <td>[able, abilities, ability, abler, ablest, ably...</td>\n",
       "      <td>[(able, jj), (abilities, nn), (ability, nn), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>[abnormal, abnormalities, abnormality, abnorma...</td>\n",
       "      <td>[(abnormal, jj), (abnormalities, nn), (abnorma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>aboard</td>\n",
       "      <td>[aboard]</td>\n",
       "      <td>[(aboard, ii), (aboard, rr)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>abolish</td>\n",
       "      <td>[abolish, abolished, abolishes, abolishing]</td>\n",
       "      <td>[(abolish, vv), (abolished, vv), (abolishes, v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     family                                              forms  \\\n",
       "0   abandon  [abandon, abandoned, abandoning, abandonment, ...   \n",
       "1      able  [able, abilities, ability, abler, ablest, ably...   \n",
       "2  abnormal  [abnormal, abnormalities, abnormality, abnorma...   \n",
       "3    aboard                                           [aboard]   \n",
       "4   abolish        [abolish, abolished, abolishes, abolishing]   \n",
       "\n",
       "                                            form_POS  \n",
       "0  [(abandon, vv), (abandon, nn), (abandoned, vv)...  \n",
       "1  [(able, jj), (abilities, nn), (ability, nn), (...  \n",
       "2  [(abnormal, jj), (abnormalities, nn), (abnorma...  \n",
       "3                       [(aboard, ii), (aboard, rr)]  \n",
       "4  [(abolish, vv), (abolished, vv), (abolishes, v...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rearranging columns for clarity\n",
    "mid_freq_fams = mid_freq_fams[['family', 'forms', 'form_POS']]\n",
    "mid_freq_fams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking derivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>forms</th>\n",
       "      <th>form_POS</th>\n",
       "      <th>unique_POS</th>\n",
       "      <th>POS_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>abandon</td>\n",
       "      <td>[abandon, abandoned, abandoning, abandonment, ...</td>\n",
       "      <td>[(abandon, vv), (abandon, nn), (abandoned, vv)...</td>\n",
       "      <td>[nn, jj, vv]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>able</td>\n",
       "      <td>[able, abilities, ability, abler, ablest, ably...</td>\n",
       "      <td>[(able, jj), (abilities, nn), (ability, nn), (...</td>\n",
       "      <td>[nn, jj, rr]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>[abnormal, abnormalities, abnormality, abnorma...</td>\n",
       "      <td>[(abnormal, jj), (abnormalities, nn), (abnorma...</td>\n",
       "      <td>[nn, jj, rr]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>aboard</td>\n",
       "      <td>[aboard]</td>\n",
       "      <td>[(aboard, ii), (aboard, rr)]</td>\n",
       "      <td>[rr]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>abolish</td>\n",
       "      <td>[abolish, abolished, abolishes, abolishing]</td>\n",
       "      <td>[(abolish, vv), (abolished, vv), (abolishes, v...</td>\n",
       "      <td>[vv]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     family                                              forms  \\\n",
       "0   abandon  [abandon, abandoned, abandoning, abandonment, ...   \n",
       "1      able  [able, abilities, ability, abler, ablest, ably...   \n",
       "2  abnormal  [abnormal, abnormalities, abnormality, abnorma...   \n",
       "3    aboard                                           [aboard]   \n",
       "4   abolish        [abolish, abolished, abolishes, abolishing]   \n",
       "\n",
       "                                            form_POS    unique_POS  POS_len  \n",
       "0  [(abandon, vv), (abandon, nn), (abandoned, vv)...  [nn, jj, vv]        3  \n",
       "1  [(able, jj), (abilities, nn), (ability, nn), (...  [nn, jj, rr]        3  \n",
       "2  [(abnormal, jj), (abnormalities, nn), (abnorma...  [nn, jj, rr]        3  \n",
       "3                       [(aboard, ii), (aboard, rr)]          [rr]        1  \n",
       "4  [(abolish, vv), (abolished, vv), (abolishes, v...          [vv]        1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating columns showing different parts of speech and how many there are\n",
    "mid_freq_fams['unique_POS'] = [list(set(dict(x).values())) for x in mid_freq_fams['form_POS']] #only unique POS\n",
    "mid_freq_fams['POS_len'] = [len(x) for x in mid_freq_fams['unique_POS']] #number of different POS\n",
    "mid_freq_fams.head()\n",
    "\n",
    "#NOTE: This does not take into account how many different forms of the same POS there may be, \n",
    "# e.g. how many adj forms in a lemma family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ii', 'nn', 'pp', 'pn', 'at', 'mf', 'da', 'rr', 'md', 'cs', 'jj', 'uh', 'ap', 'dd', 'db', 'mc', 'cc', 'vv']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['ii', 'pp', 'pn', 'at', 'mf', 'da', 'md', 'cs', 'uh', 'ap', 'dd', 'db', 'mc', 'cc']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing all form_POS except for nn, jj, rr, vv (nouns, adjectives, adverbs, verbs)\n",
    "all_POS = list(set([x for y in mid_freq_fams.unique_POS for x in y]))\n",
    "all_POS\n",
    "removal = [x for x in all_POS if x!='nn' and x!='jj' and x!='rr' and x!='vv']\n",
    "removal\n",
    "mid_freq_fams['core_POS'] = mid_freq_fams['form_POS'].apply(lambda x: [i for i in x if i[1] not in removal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns again showing different CORE parts of speech and how many there are\n",
    "mid_freq_fams['core_unique_POS'] = [list(set(dict(x).values())) for x in mid_freq_fams['core_POS']] #only unique POS\n",
    "mid_freq_fams['core_POS_len'] = [len(x) for x in mid_freq_fams['core_unique_POS']] #number of different POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1486\n",
       "1    1472\n",
       "2    1325\n",
       "4     399\n",
       "0      32\n",
       "Name: core_POS_len, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how many mid-freq families have forms in four word classes\n",
    "mid_freq_fams.core_POS_len.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe of the 4-derivation subset of mid-frequency items\n",
    "deriv4 = mid_freq_fams.loc[mid_freq_fams.core_POS_len == 4].reset_index(inplace = False, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     386\n",
       "False     13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And also narrowing to just those lemma families which have all four major word classes: nn, jj, rr, vv\n",
    "(deriv4.form_POS == deriv4.core_POS).value_counts()\n",
    "deriv4 = deriv4.loc[deriv4.form_POS == deriv4.core_POS,:]\n",
    "len(deriv4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>forms</th>\n",
       "      <th>form_POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>[abstract, abstracted, abstractedly, abstracti...</td>\n",
       "      <td>[(abstract, jj), (abstract, nn), (abstract, vv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>accept</td>\n",
       "      <td>[accept, acceptability, acceptable, acceptably...</td>\n",
       "      <td>[(accept, vv), (acceptability, nn), (acceptabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>accuse</td>\n",
       "      <td>[accuse, accusation, accusations, accused, acc...</td>\n",
       "      <td>[(accuse, vv), (accusation, nn), (accusations,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>admire</td>\n",
       "      <td>[admire, admirable, admirably, admiration, adm...</td>\n",
       "      <td>[(admire, vv), (admirable, jj), (admirably, rr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>advise</td>\n",
       "      <td>[advise, advisability, advisable, advisably, a...</td>\n",
       "      <td>[(advise, vv), (advisability, nn), (advisable,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     family                                              forms  \\\n",
       "0  abstract  [abstract, abstracted, abstractedly, abstracti...   \n",
       "1    accept  [accept, acceptability, acceptable, acceptably...   \n",
       "2    accuse  [accuse, accusation, accusations, accused, acc...   \n",
       "4    admire  [admire, admirable, admirably, admiration, adm...   \n",
       "5    advise  [advise, advisability, advisable, advisably, a...   \n",
       "\n",
       "                                            form_POS  \n",
       "0  [(abstract, jj), (abstract, nn), (abstract, vv...  \n",
       "1  [(accept, vv), (acceptability, nn), (acceptabl...  \n",
       "2  [(accuse, vv), (accusation, nn), (accusations,...  \n",
       "4  [(admire, vv), (admirable, jj), (admirably, rr...  \n",
       "5  [(advise, vv), (advisability, nn), (advisable,...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping redundant columns\n",
    "deriv4 = deriv4.drop(['unique_POS', 'POS_len', 'core_unique_POS', 'core_POS','core_POS_len'], axis=1)\n",
    "deriv4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset narrowing\n",
    "After first round of COCA analysis, 386 lemma families is too big a dataset, so further narrowing based on the following parameters:\n",
    "- minimum of 4 mid-frequency derivations (though not necessarily all of nn, jj, rr, vv)\n",
    "- no forms in the top 100 most common lemmas (as lemma like 'time' is so frequent as to skew all data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how many items from each deriv4 family are in mid_freq\n",
    "\n",
    "# Create new column with only the lemma family items which are in the mid_freq too\n",
    "mid_freq_list = sorted(mid_freq.lemma_POS.to_list())\n",
    "deriv4['form_in_midfreq'] = deriv4.form_POS.apply(lambda x: [i for i in x if i in mid_freq_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    142\n",
       "2    130\n",
       "3     71\n",
       "4     31\n",
       "5      8\n",
       "6      2\n",
       "9      1\n",
       "0      1\n",
       "Name: len_form_in_midfreq, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking number of different form_in_midfreq for each of the families\n",
    "deriv4['len_form_in_midfreq'] = [len(x) for x in deriv4['form_in_midfreq']]\n",
    "deriv4.len_form_in_midfreq.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary from coca_df of lemma_POS:wordPOS - give it the word_POS and returns the lemma_POS\n",
    "word_POS_lemma_POS_dict = pd.Series(coca_df.lemma_POS.values,coca_df.word_POS).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column of lemma_in_midfreq - should be nearly the same or exactly the same as form_in_midfreq\n",
    "# but with inflections combined\n",
    "deriv4['lemma_in_midfreq'] = deriv4['form_in_midfreq'].apply(lambda i:list(set([word_POS_lemma_POS_dict[x] for x in i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And use same idea to calculate lemma_POS column (necessary for later data analysis)\n",
    "deriv4['lemma_POS'] = deriv4['form_POS'].apply(lambda i:list(set([word_POS_lemma_POS_dict[x] for x in i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>forms</th>\n",
       "      <th>form_POS</th>\n",
       "      <th>form_in_midfreq</th>\n",
       "      <th>len_form_in_midfreq</th>\n",
       "      <th>lemma_in_midfreq</th>\n",
       "      <th>lemma_POS</th>\n",
       "      <th>len_lemma_in_midfreq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>[abstract, abstracted, abstractedly, abstracti...</td>\n",
       "      <td>[(abstract, jj), (abstract, nn), (abstract, vv...</td>\n",
       "      <td>[(abstract, jj), (abstraction, nn)]</td>\n",
       "      <td>2</td>\n",
       "      <td>[(abstraction, nn), (abstract, jj)]</td>\n",
       "      <td>[(abstract, nn), (abstractness, nn), (abstract...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>accept</td>\n",
       "      <td>[accept, acceptability, acceptable, acceptably...</td>\n",
       "      <td>[(accept, vv), (acceptability, nn), (acceptabl...</td>\n",
       "      <td>[(acceptable, jj), (acceptance, nn), (accepted...</td>\n",
       "      <td>4</td>\n",
       "      <td>[(accepted, jj), (acceptance, nn), (unacceptab...</td>\n",
       "      <td>[(accepted, jj), (unacceptability, nn), (unacc...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>accuse</td>\n",
       "      <td>[accuse, accusation, accusations, accused, acc...</td>\n",
       "      <td>[(accuse, vv), (accusation, nn), (accusations,...</td>\n",
       "      <td>[(accuse, vv), (accusation, nn)]</td>\n",
       "      <td>2</td>\n",
       "      <td>[(accusation, nn), (accuse, vv)]</td>\n",
       "      <td>[(accusation, nn), (accuser, nn), (accusingly,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>admire</td>\n",
       "      <td>[admire, admirable, admirably, admiration, adm...</td>\n",
       "      <td>[(admire, vv), (admirable, jj), (admirably, rr...</td>\n",
       "      <td>[(admire, vv), (admiration, nn)]</td>\n",
       "      <td>2</td>\n",
       "      <td>[(admiration, nn), (admire, vv)]</td>\n",
       "      <td>[(admiringly, rr), (admirer, nn), (admiration,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>advise</td>\n",
       "      <td>[advise, advisability, advisable, advisably, a...</td>\n",
       "      <td>[(advise, vv), (advisability, nn), (advisable,...</td>\n",
       "      <td>[(advise, vv), (adviser, nn), (advisor, nn), (...</td>\n",
       "      <td>4</td>\n",
       "      <td>[(adviser, nn), (advise, vv), (advisory, jj), ...</td>\n",
       "      <td>[(advisable, jj), (advisement, nn), (inadvisab...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     family                                              forms  \\\n",
       "0  abstract  [abstract, abstracted, abstractedly, abstracti...   \n",
       "1    accept  [accept, acceptability, acceptable, acceptably...   \n",
       "2    accuse  [accuse, accusation, accusations, accused, acc...   \n",
       "4    admire  [admire, admirable, admirably, admiration, adm...   \n",
       "5    advise  [advise, advisability, advisable, advisably, a...   \n",
       "\n",
       "                                            form_POS  \\\n",
       "0  [(abstract, jj), (abstract, nn), (abstract, vv...   \n",
       "1  [(accept, vv), (acceptability, nn), (acceptabl...   \n",
       "2  [(accuse, vv), (accusation, nn), (accusations,...   \n",
       "4  [(admire, vv), (admirable, jj), (admirably, rr...   \n",
       "5  [(advise, vv), (advisability, nn), (advisable,...   \n",
       "\n",
       "                                     form_in_midfreq  len_form_in_midfreq  \\\n",
       "0                [(abstract, jj), (abstraction, nn)]                    2   \n",
       "1  [(acceptable, jj), (acceptance, nn), (accepted...                    4   \n",
       "2                   [(accuse, vv), (accusation, nn)]                    2   \n",
       "4                   [(admire, vv), (admiration, nn)]                    2   \n",
       "5  [(advise, vv), (adviser, nn), (advisor, nn), (...                    4   \n",
       "\n",
       "                                    lemma_in_midfreq  \\\n",
       "0                [(abstraction, nn), (abstract, jj)]   \n",
       "1  [(accepted, jj), (acceptance, nn), (unacceptab...   \n",
       "2                   [(accusation, nn), (accuse, vv)]   \n",
       "4                   [(admiration, nn), (admire, vv)]   \n",
       "5  [(adviser, nn), (advise, vv), (advisory, jj), ...   \n",
       "\n",
       "                                           lemma_POS  len_lemma_in_midfreq  \n",
       "0  [(abstract, nn), (abstractness, nn), (abstract...                     2  \n",
       "1  [(accepted, jj), (unacceptability, nn), (unacc...                     4  \n",
       "2  [(accusation, nn), (accuser, nn), (accusingly,...                     2  \n",
       "4  [(admiringly, rr), (admirer, nn), (admiration,...                     2  \n",
       "5  [(advisable, jj), (advisement, nn), (inadvisab...                     4  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deriv4['len_lemma_in_midfreq'] = [len(x) for x in deriv4['lemma_in_midfreq']]\n",
    "deriv4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all lemma_POS except for jj, nn, rr, vv\n",
    "all_POS = list(set([x for y in mid_freq_fams.unique_POS for x in y]))\n",
    "removal = [x for x in all_POS if x!='nn' and x!='jj' and x!='rr' and x!='vv']\n",
    "deriv4['core_POS'] = deriv4['lemma_in_midfreq'].apply(lambda x: [i for i in x if i[1] not in removal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many families have 4+ mid-freq derivations\n",
    "deriv4['core_POS_only'] = [list(dict(x).values()) for x in deriv4['core_POS']]\n",
    "deriv4['len_core_POS_only'] = [len(x) for x in deriv4.core_POS_only]\n",
    "len(deriv4.loc[deriv4.len_core_POS_only >= 4]) # This is a reasonable number of families for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(the, at)</td>\n",
       "      <td>20698151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(be, vv)</td>\n",
       "      <td>10782841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(of, ii)</td>\n",
       "      <td>9916794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(and, cc)</td>\n",
       "      <td>9875027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>(a, at)</td>\n",
       "      <td>9523432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lemma      freq\n",
       "1  (the, at)  20698151\n",
       "2   (be, vv)  10782841\n",
       "3   (of, ii)   9916794\n",
       "4  (and, cc)   9875027\n",
       "5    (a, at)   9523432"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing any items with lemma in top 100 most frequent lemmas\n",
    "\n",
    "# Create ranking of lemmas\n",
    "lemma_ranking = pd.DataFrame.from_dict(lemma_dict, orient = 'index')\n",
    "lemma_ranking = lemma_ranking.reset_index(drop=False)\n",
    "lemma_ranking.index += 1\n",
    "lemma_ranking = lemma_ranking.rename(columns={\"index\": \"lemma\", 0: \"freq\"})\n",
    "lemma_ranking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lemma_rank dict and column\n",
    "lemma_rank_dict = dict(zip(lemma_ranking.lemma,lemma_ranking.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most frequent lemma form in each family\n",
    "deriv4['most_freq_lemma'] = deriv4.lemma_POS.apply(lambda row: [(x,lemma_dict[x]) for x in row])\n",
    "deriv4['most_freq_lemma'] = deriv4['most_freq_lemma'].apply(lambda row: sorted(row,key=lambda x: x[1],reverse=True))\n",
    "deriv4['most_freq_lemma'] = [x[0][0] for x in deriv4['most_freq_lemma']]\n",
    "\n",
    "deriv4['lemma_rank'] = deriv4.most_freq_lemma.map(lemma_rank_dict)\n",
    "deriv4 = deriv4.sort_values(by='lemma_rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>forms</th>\n",
       "      <th>form_POS</th>\n",
       "      <th>form_in_midfreq</th>\n",
       "      <th>len_form_in_midfreq</th>\n",
       "      <th>lemma_in_midfreq</th>\n",
       "      <th>lemma_POS</th>\n",
       "      <th>len_lemma_in_midfreq</th>\n",
       "      <th>core_POS</th>\n",
       "      <th>core_POS_only</th>\n",
       "      <th>len_core_POS_only</th>\n",
       "      <th>most_freq_lemma</th>\n",
       "      <th>lemma_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>art</td>\n",
       "      <td>[art, artist, artistic, artistically, artistri...</td>\n",
       "      <td>[(art, nn), (art, vv), (artist, nn), (artistic...</td>\n",
       "      <td>[(artistic, jj)]</td>\n",
       "      <td>1</td>\n",
       "      <td>[(artistic, jj)]</td>\n",
       "      <td>[(artistry, nn), (be, vv), (art, nn), (artisti...</td>\n",
       "      <td>1</td>\n",
       "      <td>[(artistic, jj)]</td>\n",
       "      <td>[jj]</td>\n",
       "      <td>1</td>\n",
       "      <td>(be, vv)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312</td>\n",
       "      <td>say</td>\n",
       "      <td>[say, said, saying, sayings, says, sez, unsaid...</td>\n",
       "      <td>[(say, vv), (say, nn), (say, rr), (said, vv), ...</td>\n",
       "      <td>[(say, nn)]</td>\n",
       "      <td>1</td>\n",
       "      <td>[(say, nn)]</td>\n",
       "      <td>[(say, nn), (saying, nn), (unsayable, jj), (sa...</td>\n",
       "      <td>1</td>\n",
       "      <td>[(say, nn)]</td>\n",
       "      <td>[nn]</td>\n",
       "      <td>1</td>\n",
       "      <td>(say, vv)</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>will</td>\n",
       "      <td>[will, ll, unwilling, unwillingly, unwillingne...</td>\n",
       "      <td>[(will, vv), (will, nn), (unwilling, jj), (unw...</td>\n",
       "      <td>[(unwilling, jj), (willingness, nn)]</td>\n",
       "      <td>2</td>\n",
       "      <td>[(unwilling, jj), (willingness, nn)]</td>\n",
       "      <td>[(willingly, rr), (willing, jj), (unwillingly,...</td>\n",
       "      <td>2</td>\n",
       "      <td>[(unwilling, jj), (willingness, nn)]</td>\n",
       "      <td>[jj, nn]</td>\n",
       "      <td>2</td>\n",
       "      <td>(will, vv)</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>time</td>\n",
       "      <td>[time, anytime, timed, timeless, timelessness,...</td>\n",
       "      <td>[(time, nn), (time, vv), (anytime, rr), (timed...</td>\n",
       "      <td>[(time, vv), (anytime, rr), (timely, jj), (tim...</td>\n",
       "      <td>4</td>\n",
       "      <td>[(timing, nn), (time, vv), (anytime, rr), (tim...</td>\n",
       "      <td>[(timeliness, nn), (timing, nn), (anytime, rr)...</td>\n",
       "      <td>4</td>\n",
       "      <td>[(timing, nn), (time, vv), (anytime, rr), (tim...</td>\n",
       "      <td>[nn, vv, rr, jj]</td>\n",
       "      <td>4</td>\n",
       "      <td>(time, nn)</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>know</td>\n",
       "      <td>[know, dunno, knew, knowable, knowed, knowing,...</td>\n",
       "      <td>[(know, vv), (know, nn), (knew, vv), (knowable...</td>\n",
       "      <td>[(known, jj), (unknown, jj)]</td>\n",
       "      <td>2</td>\n",
       "      <td>[(unknown, jj), (known, jj)]</td>\n",
       "      <td>[(unknowing, jj), (knowingly, rr), (unknown, n...</td>\n",
       "      <td>2</td>\n",
       "      <td>[(unknown, jj), (known, jj)]</td>\n",
       "      <td>[jj, jj]</td>\n",
       "      <td>2</td>\n",
       "      <td>(know, vv)</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    family                                              forms  \\\n",
       "18     art  [art, artist, artistic, artistically, artistri...   \n",
       "312    say  [say, said, saying, sayings, says, sez, unsaid...   \n",
       "394   will  [will, ll, unwilling, unwillingly, unwillingne...   \n",
       "370   time  [time, anytime, timed, timeless, timelessness,...   \n",
       "207   know  [know, dunno, knew, knowable, knowed, knowing,...   \n",
       "\n",
       "                                              form_POS  \\\n",
       "18   [(art, nn), (art, vv), (artist, nn), (artistic...   \n",
       "312  [(say, vv), (say, nn), (say, rr), (said, vv), ...   \n",
       "394  [(will, vv), (will, nn), (unwilling, jj), (unw...   \n",
       "370  [(time, nn), (time, vv), (anytime, rr), (timed...   \n",
       "207  [(know, vv), (know, nn), (knew, vv), (knowable...   \n",
       "\n",
       "                                       form_in_midfreq  len_form_in_midfreq  \\\n",
       "18                                    [(artistic, jj)]                    1   \n",
       "312                                        [(say, nn)]                    1   \n",
       "394               [(unwilling, jj), (willingness, nn)]                    2   \n",
       "370  [(time, vv), (anytime, rr), (timely, jj), (tim...                    4   \n",
       "207                       [(known, jj), (unknown, jj)]                    2   \n",
       "\n",
       "                                      lemma_in_midfreq  \\\n",
       "18                                    [(artistic, jj)]   \n",
       "312                                        [(say, nn)]   \n",
       "394               [(unwilling, jj), (willingness, nn)]   \n",
       "370  [(timing, nn), (time, vv), (anytime, rr), (tim...   \n",
       "207                       [(unknown, jj), (known, jj)]   \n",
       "\n",
       "                                             lemma_POS  len_lemma_in_midfreq  \\\n",
       "18   [(artistry, nn), (be, vv), (art, nn), (artisti...                     1   \n",
       "312  [(say, nn), (saying, nn), (unsayable, jj), (sa...                     1   \n",
       "394  [(willingly, rr), (willing, jj), (unwillingly,...                     2   \n",
       "370  [(timeliness, nn), (timing, nn), (anytime, rr)...                     4   \n",
       "207  [(unknowing, jj), (knowingly, rr), (unknown, n...                     2   \n",
       "\n",
       "                                              core_POS     core_POS_only  \\\n",
       "18                                    [(artistic, jj)]              [jj]   \n",
       "312                                        [(say, nn)]              [nn]   \n",
       "394               [(unwilling, jj), (willingness, nn)]          [jj, nn]   \n",
       "370  [(timing, nn), (time, vv), (anytime, rr), (tim...  [nn, vv, rr, jj]   \n",
       "207                       [(unknown, jj), (known, jj)]          [jj, jj]   \n",
       "\n",
       "     len_core_POS_only most_freq_lemma  lemma_rank  \n",
       "18                   1        (be, vv)           2  \n",
       "312                  1       (say, vv)          22  \n",
       "394                  2      (will, vv)          47  \n",
       "370                  4      (time, nn)          51  \n",
       "207                  2      (know, vv)          61  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deriv4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final narrowing based on above criteria to create dataframe of COCA key families\n",
    "coca_key = deriv4.loc[deriv4.len_core_POS_only >= 4]\n",
    "coca_key = coca_key.loc[coca_key.lemma_rank > 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier: 'Reason'\n",
    "After further analysis at a later stage when compiling the concordance, it as discovered that the lemma 'reason' (nn) was an outlier, accounting for 27.8% of the total dataset. As can be seen below, this is likely due to a number of factors:\n",
    "- the discrepancy between the frequency of the noun form (lemma rank 413) and the other most common forms.\n",
    "- its inclusion in task prompts (e.g. 'give reasons...') and utility in the genre of argumentative essays.\n",
    "\n",
    "As such, the 'reason' family has been excluded from analysis since the likelihood of any other form being used, or an inaccurate form being used, is minimal for learners in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>413</td>\n",
       "      <td>(reason, nn)</td>\n",
       "      <td>91350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lemma   freq\n",
       "413  (reason, nn)  91350"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6617</td>\n",
       "      <td>(reason, vv)</td>\n",
       "      <td>3394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lemma  freq\n",
       "6617  (reason, vv)  3394"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2915</td>\n",
       "      <td>(reasonable, jj)</td>\n",
       "      <td>11469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lemma   freq\n",
       "2915  (reasonable, jj)  11469"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_ranking.loc[lemma_ranking.lemma == ('reason','nn')]\n",
    "lemma_ranking.loc[lemma_ranking.lemma == ('reason','vv')]\n",
    "lemma_ranking.loc[lemma_ranking.lemma == ('reasonable','jj')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>freq</th>\n",
       "      <th>spoken_freq</th>\n",
       "      <th>acad_per_M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>reason</td>\n",
       "      <td>reason</td>\n",
       "      <td>nn1</td>\n",
       "      <td>81997</td>\n",
       "      <td>21441</td>\n",
       "      <td>170.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1084</td>\n",
       "      <td>reasons</td>\n",
       "      <td>reason</td>\n",
       "      <td>nn2</td>\n",
       "      <td>39930</td>\n",
       "      <td>9136</td>\n",
       "      <td>143.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12119</td>\n",
       "      <td>reason</td>\n",
       "      <td>reason</td>\n",
       "      <td>vv0</td>\n",
       "      <td>2046</td>\n",
       "      <td>285</td>\n",
       "      <td>6.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15216</td>\n",
       "      <td>reasoned</td>\n",
       "      <td>reason</td>\n",
       "      <td>vvd</td>\n",
       "      <td>1410</td>\n",
       "      <td>45</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46064</td>\n",
       "      <td>reasons</td>\n",
       "      <td>reason</td>\n",
       "      <td>vvz</td>\n",
       "      <td>154</td>\n",
       "      <td>13</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48612</td>\n",
       "      <td>reasoned</td>\n",
       "      <td>reason</td>\n",
       "      <td>vvn</td>\n",
       "      <td>134</td>\n",
       "      <td>7</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word   lemma  POS   freq  spoken_freq  acad_per_M\n",
       "rank                                                        \n",
       "500      reason  reason  nn1  81997        21441      170.43\n",
       "1084    reasons  reason  nn2  39930         9136      143.35\n",
       "12119    reason  reason  vv0   2046          285        6.35\n",
       "15216  reasoned  reason  vvd   1410           45        4.50\n",
       "46064   reasons  reason  vvz    154           13        0.33\n",
       "48612  reasoned  reason  vvn    134            7        0.64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>freq</th>\n",
       "      <th>spoken_freq</th>\n",
       "      <th>acad_per_M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2867</td>\n",
       "      <td>reasonable</td>\n",
       "      <td>reasonable</td>\n",
       "      <td>jj</td>\n",
       "      <td>14739</td>\n",
       "      <td>3270</td>\n",
       "      <td>51.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46692</td>\n",
       "      <td>reasonable</td>\n",
       "      <td>reasonable</td>\n",
       "      <td>rr</td>\n",
       "      <td>149</td>\n",
       "      <td>25</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word       lemma POS   freq  spoken_freq  acad_per_M\n",
       "rank                                                             \n",
       "2867   reasonable  reasonable  jj  14739         3270       51.61\n",
       "46692  reasonable  reasonable  rr    149           25        0.38"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analysis of academic word per million of 'reason'\n",
    "reason = pd.read_csv('COCA_frequency_info.txt', skiprows=2, encoding=\"utf8\", sep='\\t', na_filter=False)\n",
    "reason = reason[['ID', 'w1', 'L1', 'c1', 'coca','fc1','pc5']]\n",
    "reason.columns = ['rank', 'word', 'lemma', 'POS', 'freq','spoken_freq','acad_per_M']\n",
    "reason = reason.set_index('rank')\n",
    "reason.loc[reason.lemma == 'reason']\n",
    "reason.loc[reason.lemma == 'reasonable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing of 'reason family' from key families dataset\n",
    "coca_key = coca_key.loc[coca_key.family != 'reason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['accept', 'advise', 'back', 'collaborate', 'compete', 'confuse', 'construct', 'continue', 'correct', 'embarrass', 'equal', 'excite', 'expect', 'frustrate', 'heat', 'infect', 'intense', 'nation', 'open', 'precede', 'predict', 'select', 'special', 'structure', 'vary', 'wide']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coca_key)\n",
    "sorted(coca_key.family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of word types\n",
    "sum([len(x) for x in coca_key.form_POS])\n",
    "\n",
    "# Total number of lemma types\n",
    "sum([len(x) for x in coca_key.lemma_POS])\n",
    "\n",
    "# Total number of mid-freq lemma types\n",
    "sum([len(x) for x in coca_key.lemma_in_midfreq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "coca_key.to_pickle(\"coca_key.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next notebook: 2_PELIC_dataset.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
