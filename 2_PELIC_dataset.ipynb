{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2_PELIC dataset\n",
    "\n",
    "\n",
    "## Finding occurrences of use of 'key' family items in the PELIC corpus\n",
    "\n",
    "**Note:** The pickle file containing the written section of the PELIC corpus used in this notebook is not currently publicly available. However, it will be made publicly available in the summer of 2020 and can be downloaded from the [Pitt ELI Data Mining Group github page](https://github.com/ELI-Data-Mining-Group/Pitt-ELI-Corpus).\n",
    "\n",
    "#### Sections of the notebook\n",
    "- [Initial setup](#Initial-setup)\n",
    "- [Spelling correction](#Spelling-correction)\n",
    "- [Key families in PELIC](#Key-families-in-PELIC)\n",
    "- [Key family forms](#Key-family-forms)\n",
    "- [Narrowing dataset](#Narrowing-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary modules\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import pickle as pkl\n",
    "import csv\n",
    "\n",
    "# Setting preferred notebook format\n",
    "%pprint # Turn off pretty printing\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # Shows all output, not just last item\n",
    "pd.set_option('display.max_columns', 999) # Allow viewing of all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>forms</th>\n",
       "      <th>form_POS</th>\n",
       "      <th>form_in_midfreq</th>\n",
       "      <th>len_form_in_midfreq</th>\n",
       "      <th>lemma_in_midfreq</th>\n",
       "      <th>lemma_POS</th>\n",
       "      <th>len_lemma_in_midfreq</th>\n",
       "      <th>core_POS</th>\n",
       "      <th>core_POS_only</th>\n",
       "      <th>len_core_POS_only</th>\n",
       "      <th>most_freq_lemma</th>\n",
       "      <th>lemma_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>back</td>\n",
       "      <td>[back, backed, backer, backers, backing, backs...</td>\n",
       "      <td>[(back, rr), (back, nn), (back, vv), (back, jj...</td>\n",
       "      <td>[(back, vv), (backing, nn), (backward, rr), (b...</td>\n",
       "      <td>4</td>\n",
       "      <td>[(backward, rr), (back, vv), (backing, nn), (b...</td>\n",
       "      <td>[(back, jj), (back, rr), (backing, nn), (backw...</td>\n",
       "      <td>4</td>\n",
       "      <td>[(backward, rr), (back, vv), (backing, nn), (b...</td>\n",
       "      <td>[rr, vv, nn, rr]</td>\n",
       "      <td>4</td>\n",
       "      <td>(back, rr)</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>nation</td>\n",
       "      <td>[nation, national, nationalisation, nationalis...</td>\n",
       "      <td>[(nation, nn), (national, jj), (national, nn),...</td>\n",
       "      <td>[(nationalism, nn), (nationalist, jj), (nation...</td>\n",
       "      <td>6</td>\n",
       "      <td>[(nationwide, rr), (nationalist, nn), (nationa...</td>\n",
       "      <td>[(nationwide, rr), (nationalize, vv), (nation,...</td>\n",
       "      <td>6</td>\n",
       "      <td>[(nationwide, rr), (nationalist, nn), (nationa...</td>\n",
       "      <td>[jj, jj, nn, rr]</td>\n",
       "      <td>4</td>\n",
       "      <td>(national, jj)</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>open</td>\n",
       "      <td>[open, opened, opener, openers, opening, openi...</td>\n",
       "      <td>[(open, jj), (open, vv), (open, rr), (opened, ...</td>\n",
       "      <td>[(open, rr), (opener, nn), (openly, rr), (open...</td>\n",
       "      <td>5</td>\n",
       "      <td>[(open, rr), (reopen, vv), (openly, rr), (open...</td>\n",
       "      <td>[(open, jj), (reopening, nn), (open, rr), (uno...</td>\n",
       "      <td>5</td>\n",
       "      <td>[(open, rr), (reopen, vv), (openly, rr), (open...</td>\n",
       "      <td>[rr, vv, rr, nn, nn]</td>\n",
       "      <td>5</td>\n",
       "      <td>(open, vv)</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>continue</td>\n",
       "      <td>[continue, continual, continually, continuance...</td>\n",
       "      <td>[(continue, vv), (continual, jj), (continually...</td>\n",
       "      <td>[(continually, rr), (continued, jj), (continui...</td>\n",
       "      <td>6</td>\n",
       "      <td>[(continuing, jj), (continuity, nn), (continua...</td>\n",
       "      <td>[(continuing, jj), (continuity, nn), (continua...</td>\n",
       "      <td>6</td>\n",
       "      <td>[(continuing, jj), (continuity, nn), (continua...</td>\n",
       "      <td>[jj, nn, rr, rr, jj, jj]</td>\n",
       "      <td>6</td>\n",
       "      <td>(continue, vv)</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>expect</td>\n",
       "      <td>[expect, expectancies, expectancy, expectant, ...</td>\n",
       "      <td>[(expect, vv), (expectancies, nn), (expectancy...</td>\n",
       "      <td>[(expectancy, nn), (expected, jj), (unexpected...</td>\n",
       "      <td>4</td>\n",
       "      <td>[(unexpected, jj), (unexpectedly, rr), (expect...</td>\n",
       "      <td>[(expectation, nn), (unexpectedly, rr), (unexp...</td>\n",
       "      <td>4</td>\n",
       "      <td>[(unexpected, jj), (unexpectedly, rr), (expect...</td>\n",
       "      <td>[jj, rr, jj, nn]</td>\n",
       "      <td>4</td>\n",
       "      <td>(expect, vv)</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       family                                              forms  \\\n",
       "25       back  [back, backed, backer, backers, backing, backs...   \n",
       "242    nation  [nation, national, nationalisation, nationalis...   \n",
       "253      open  [open, opened, opener, openers, opening, openi...   \n",
       "72   continue  [continue, continual, continually, continuance...   \n",
       "140    expect  [expect, expectancies, expectancy, expectant, ...   \n",
       "\n",
       "                                              form_POS  \\\n",
       "25   [(back, rr), (back, nn), (back, vv), (back, jj...   \n",
       "242  [(nation, nn), (national, jj), (national, nn),...   \n",
       "253  [(open, jj), (open, vv), (open, rr), (opened, ...   \n",
       "72   [(continue, vv), (continual, jj), (continually...   \n",
       "140  [(expect, vv), (expectancies, nn), (expectancy...   \n",
       "\n",
       "                                       form_in_midfreq  len_form_in_midfreq  \\\n",
       "25   [(back, vv), (backing, nn), (backward, rr), (b...                    4   \n",
       "242  [(nationalism, nn), (nationalist, jj), (nation...                    6   \n",
       "253  [(open, rr), (opener, nn), (openly, rr), (open...                    5   \n",
       "72   [(continually, rr), (continued, jj), (continui...                    6   \n",
       "140  [(expectancy, nn), (expected, jj), (unexpected...                    4   \n",
       "\n",
       "                                      lemma_in_midfreq  \\\n",
       "25   [(backward, rr), (back, vv), (backing, nn), (b...   \n",
       "242  [(nationwide, rr), (nationalist, nn), (nationa...   \n",
       "253  [(open, rr), (reopen, vv), (openly, rr), (open...   \n",
       "72   [(continuing, jj), (continuity, nn), (continua...   \n",
       "140  [(unexpected, jj), (unexpectedly, rr), (expect...   \n",
       "\n",
       "                                             lemma_POS  len_lemma_in_midfreq  \\\n",
       "25   [(back, jj), (back, rr), (backing, nn), (backw...                     4   \n",
       "242  [(nationwide, rr), (nationalize, vv), (nation,...                     6   \n",
       "253  [(open, jj), (reopening, nn), (open, rr), (uno...                     5   \n",
       "72   [(continuing, jj), (continuity, nn), (continua...                     6   \n",
       "140  [(expectation, nn), (unexpectedly, rr), (unexp...                     4   \n",
       "\n",
       "                                              core_POS  \\\n",
       "25   [(backward, rr), (back, vv), (backing, nn), (b...   \n",
       "242  [(nationwide, rr), (nationalist, nn), (nationa...   \n",
       "253  [(open, rr), (reopen, vv), (openly, rr), (open...   \n",
       "72   [(continuing, jj), (continuity, nn), (continua...   \n",
       "140  [(unexpected, jj), (unexpectedly, rr), (expect...   \n",
       "\n",
       "                core_POS_only  len_core_POS_only most_freq_lemma  lemma_rank  \n",
       "25           [rr, vv, nn, rr]                  4      (back, rr)         109  \n",
       "242          [jj, jj, nn, rr]                  4  (national, jj)         220  \n",
       "253      [rr, vv, rr, nn, nn]                  5      (open, vv)         342  \n",
       "72   [jj, nn, rr, rr, jj, jj]                  6  (continue, vv)         350  \n",
       "140          [jj, rr, jj, nn]                  4    (expect, vv)         434  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>text</th>\n",
       "      <th>class_code</th>\n",
       "      <th>level_id</th>\n",
       "      <th>native_language</th>\n",
       "      <th>gender</th>\n",
       "      <th>version</th>\n",
       "      <th>toks_nltk</th>\n",
       "      <th>toks_pos</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>eq0</td>\n",
       "      <td>I met my friend Nife while I was studying in a...</td>\n",
       "      <td>g</td>\n",
       "      <td>4</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, met, my, friend, Nife, while, I, was, stud...</td>\n",
       "      <td>[(I, PRP), (met, VBD), (my, PRP$), (friend, NN...</td>\n",
       "      <td>[i, meet, my, friend, nife, while, i, be, stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>am8</td>\n",
       "      <td>Ten years ago, I met a women on the train betw...</td>\n",
       "      <td>g</td>\n",
       "      <td>4</td>\n",
       "      <td>Thai</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>[Ten, years, ago, ,, I, met, a, women, on, the...</td>\n",
       "      <td>[(Ten, CD), (years, NNS), (ago, RB), (,, ,), (...</td>\n",
       "      <td>[ten, year, ago, ,, i, meet, a, woman, on, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>dk5</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>[In, my, country, we, usually, do, n't, use, t...</td>\n",
       "      <td>[(In, IN), (my, PRP$), (country, NN), (we, PRP...</td>\n",
       "      <td>[in, my, country, we, usually, do, n't, use, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>dk5</td>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, organized, the, instructions, by, time, .]</td>\n",
       "      <td>[(I, PRP), (organized, VBD), (the, DT), (instr...</td>\n",
       "      <td>[i, organize, the, instruction, by, time, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>ad1</td>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\nSe...</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>[First, ,, prepare, a, port, ,, loose, tea, ,,...</td>\n",
       "      <td>[(First, RB), (,, ,), (prepare, VB), (a, DT), ...</td>\n",
       "      <td>[first, ,, prepare, a, port, ,, loose, tea, ,,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          anon_id                                               text  \\\n",
       "answer_id                                                              \n",
       "1             eq0  I met my friend Nife while I was studying in a...   \n",
       "2             am8  Ten years ago, I met a women on the train betw...   \n",
       "3             dk5  In my country we usually don't use tea bags. F...   \n",
       "4             dk5              I organized the instructions by time.   \n",
       "5             ad1  First, prepare a port, loose tea, and cup.\\nSe...   \n",
       "\n",
       "          class_code  level_id native_language  gender  version  \\\n",
       "answer_id                                                         \n",
       "1                  g         4          Arabic    Male        1   \n",
       "2                  g         4            Thai  Female        1   \n",
       "3                  w         4         Turkish  Female        1   \n",
       "4                  w         4         Turkish  Female        1   \n",
       "5                  w         4          Korean  Female        1   \n",
       "\n",
       "                                                   toks_nltk  \\\n",
       "answer_id                                                      \n",
       "1          [I, met, my, friend, Nife, while, I, was, stud...   \n",
       "2          [Ten, years, ago, ,, I, met, a, women, on, the...   \n",
       "3          [In, my, country, we, usually, do, n't, use, t...   \n",
       "4             [I, organized, the, instructions, by, time, .]   \n",
       "5          [First, ,, prepare, a, port, ,, loose, tea, ,,...   \n",
       "\n",
       "                                                    toks_pos  \\\n",
       "answer_id                                                      \n",
       "1          [(I, PRP), (met, VBD), (my, PRP$), (friend, NN...   \n",
       "2          [(Ten, CD), (years, NNS), (ago, RB), (,, ,), (...   \n",
       "3          [(In, IN), (my, PRP$), (country, NN), (we, PRP...   \n",
       "4          [(I, PRP), (organized, VBD), (the, DT), (instr...   \n",
       "5          [(First, RB), (,, ,), (prepare, VB), (a, DT), ...   \n",
       "\n",
       "                                                      lemmas  \n",
       "answer_id                                                     \n",
       "1          [i, meet, my, friend, nife, while, i, be, stud...  \n",
       "2          [ten, year, ago, ,, i, meet, a, woman, on, the...  \n",
       "3          [in, my, country, we, usually, do, n't, use, t...  \n",
       "4               [i, organize, the, instruction, by, time, .]  \n",
       "5          [first, ,, prepare, a, port, ,, loose, tea, ,,...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in necessary files\n",
    "\n",
    "#COCA key families data frame\n",
    "coca_key = pkl.load(open('coca_key.pkl', 'rb'))\n",
    "coca_key.head()\n",
    "\n",
    "# PELIC dataframe (written texts)\n",
    "pelic = pd.read_pickle('pelic_df.pkl')\n",
    "pelic = pelic.drop(['question_id', 'user_file_id', 'text_preanon', 'toks_re', 'toks_re_len'], axis=1)\n",
    "pelic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spelling correction\n",
    "Spelling the PELIC texts in PELIC has not been corrected in order to minimize data manipulation. However, as spelling accuracy is not the component of lexical depth being investigated here, the spelling of key words will be corrected so that such occurrences are included in the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reading in misspell_dict\n",
    "with open('misspell_dict.csv') as f:\n",
    "    reader = csv.reader(f, skipinitialspace=True)\n",
    "    misspell_dict = dict(reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This dictionary includes many spelling mispellings (the dictionary keys)  and their correct equivalents (the dictionary values), derived from multiple sources. Only a fraction of spelling mistakes in PELIC are addressed using this dictionary, but all misspellings and corrections of key words have been manually added. As with the PELIC pickle file, the misspell dict will be publically available in the summer of 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function for identifying the errors in a text\n",
    "def Errors_in_text(tokenized_text):\n",
    "    error_list = []\n",
    "    for word in tokenized_text:\n",
    "        if word.lower() in misspell_dict:\n",
    "            error_list.append(word.lower())\n",
    "    return error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function for replacing the errors in a text\n",
    "def CorrectSpelling(tokenized_text):\n",
    "    new_text = tokenized_text.copy()\n",
    "    for num in range (len(tokenized_text)):\n",
    "        if(tokenized_text[num].lower() in misspell_dict):\n",
    "            new_text[num] = misspell_dict[tokenized_text[num].lower()]\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 'errors_in_text' column with list of the errors which are also in our dictionary\n",
    "pelic['errors_in_text'] = pelic.toks_nltk.map(Errors_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 'number of errors' column for descriptive statistics\n",
    "pelic['len_errors_in_text'] = [len(x) for x in pelic['errors_in_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>text</th>\n",
       "      <th>class_code</th>\n",
       "      <th>level_id</th>\n",
       "      <th>native_language</th>\n",
       "      <th>gender</th>\n",
       "      <th>version</th>\n",
       "      <th>toks_nltk</th>\n",
       "      <th>toks_pos</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>errors_in_text</th>\n",
       "      <th>len_errors_in_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>eq0</td>\n",
       "      <td>I met my friend Nife while I was studying in a...</td>\n",
       "      <td>g</td>\n",
       "      <td>4</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, met, my, friend, Nife, while, I, was, stud...</td>\n",
       "      <td>[(I, PRP), (met, VBD), (my, PRP$), (friend, NN...</td>\n",
       "      <td>[i, meet, my, friend, nife, while, i, be, stud...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>am8</td>\n",
       "      <td>Ten years ago, I met a women on the train betw...</td>\n",
       "      <td>g</td>\n",
       "      <td>4</td>\n",
       "      <td>Thai</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>[Ten, years, ago, ,, I, met, a, women, on, the...</td>\n",
       "      <td>[(Ten, CD), (years, NNS), (ago, RB), (,, ,), (...</td>\n",
       "      <td>[ten, year, ago, ,, i, meet, a, woman, on, the...</td>\n",
       "      <td>[agin]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>dk5</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>[In, my, country, we, usually, do, n't, use, t...</td>\n",
       "      <td>[(In, IN), (my, PRP$), (country, NN), (we, PRP...</td>\n",
       "      <td>[in, my, country, we, usually, do, n't, use, t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>dk5</td>\n",
       "      <td>I organized the instructions by time.</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, organized, the, instructions, by, time, .]</td>\n",
       "      <td>[(I, PRP), (organized, VBD), (the, DT), (instr...</td>\n",
       "      <td>[i, organize, the, instruction, by, time, .]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>ad1</td>\n",
       "      <td>First, prepare a port, loose tea, and cup.\\nSe...</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>[First, ,, prepare, a, port, ,, loose, tea, ,,...</td>\n",
       "      <td>[(First, RB), (,, ,), (prepare, VB), (a, DT), ...</td>\n",
       "      <td>[first, ,, prepare, a, port, ,, loose, tea, ,,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          anon_id                                               text  \\\n",
       "answer_id                                                              \n",
       "1             eq0  I met my friend Nife while I was studying in a...   \n",
       "2             am8  Ten years ago, I met a women on the train betw...   \n",
       "3             dk5  In my country we usually don't use tea bags. F...   \n",
       "4             dk5              I organized the instructions by time.   \n",
       "5             ad1  First, prepare a port, loose tea, and cup.\\nSe...   \n",
       "\n",
       "          class_code  level_id native_language  gender  version  \\\n",
       "answer_id                                                         \n",
       "1                  g         4          Arabic    Male        1   \n",
       "2                  g         4            Thai  Female        1   \n",
       "3                  w         4         Turkish  Female        1   \n",
       "4                  w         4         Turkish  Female        1   \n",
       "5                  w         4          Korean  Female        1   \n",
       "\n",
       "                                                   toks_nltk  \\\n",
       "answer_id                                                      \n",
       "1          [I, met, my, friend, Nife, while, I, was, stud...   \n",
       "2          [Ten, years, ago, ,, I, met, a, women, on, the...   \n",
       "3          [In, my, country, we, usually, do, n't, use, t...   \n",
       "4             [I, organized, the, instructions, by, time, .]   \n",
       "5          [First, ,, prepare, a, port, ,, loose, tea, ,,...   \n",
       "\n",
       "                                                    toks_pos  \\\n",
       "answer_id                                                      \n",
       "1          [(I, PRP), (met, VBD), (my, PRP$), (friend, NN...   \n",
       "2          [(Ten, CD), (years, NNS), (ago, RB), (,, ,), (...   \n",
       "3          [(In, IN), (my, PRP$), (country, NN), (we, PRP...   \n",
       "4          [(I, PRP), (organized, VBD), (the, DT), (instr...   \n",
       "5          [(First, RB), (,, ,), (prepare, VB), (a, DT), ...   \n",
       "\n",
       "                                                      lemmas errors_in_text  \\\n",
       "answer_id                                                                     \n",
       "1          [i, meet, my, friend, nife, while, i, be, stud...             []   \n",
       "2          [ten, year, ago, ,, i, meet, a, woman, on, the...         [agin]   \n",
       "3          [in, my, country, we, usually, do, n't, use, t...             []   \n",
       "4               [i, organize, the, instruction, by, time, .]             []   \n",
       "5          [first, ,, prepare, a, port, ,, loose, tea, ,,...             []   \n",
       "\n",
       "           len_errors_in_text  \n",
       "answer_id                      \n",
       "1                           0  \n",
       "2                           1  \n",
       "3                           0  \n",
       "4                           0  \n",
       "5                           0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pelic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating column with corrected tokens\n",
    "pelic['toks_corrected'] = pelic.toks_nltk.map(CorrectSpelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2724"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2724"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting number of tokens that have been corrected (and checking this number)\n",
    "texts_with_errors = pelic.loc[pelic.len_errors_in_text != 0]\n",
    "len(texts_with_errors)\n",
    "len(texts_with_errors.loc[texts_with_errors.toks_nltk != texts_with_errors.toks_corrected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also adding a corrected lemmas column\n",
    "pelic['lem_errors'] = pelic.lemmas.map(Errors_in_text)\n",
    "pelic['len_lem_errors'] = [len(x) for x in pelic['lem_errors']]\n",
    "pelic['lems_corrected'] = pelic.lemmas.map(CorrectSpelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2628"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2628"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slightly less lemma errors as lemmatization collapsed some items\n",
    "texts_with_lem_errors = pelic.loc[pelic.len_lem_errors != 0]\n",
    "len(texts_with_lem_errors)\n",
    "len(texts_with_lem_errors.loc[texts_with_lem_errors.toks_nltk != texts_with_lem_errors.lems_corrected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also need to add a corrected toks_pos column\n",
    "pelic['toks_pos_errors'] = pelic['toks_pos'].apply(lambda x: [i for i in x if i[0] in misspell_dict])\n",
    "pelic['len_toks_pos_errors'] = [len(x) for x in pelic['toks_pos_errors']]\n",
    "pelic['toks_pos_corrected'] = pelic['toks_pos'].apply(lambda x: [tuple(CorrectSpelling(list(i))) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-pickle the updated pelic df for later use\n",
    "pelic.to_pickle(\"pelic_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key families in PELIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of the key family head lemmas\n",
    "key_lemma_list = coca_key.family.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing how many PELIC texts have one of the 27 key family head words\n",
    "mask1 = pelic.lems_corrected.apply(lambda x: any(item for item in key_lemma_list if item in x))\n",
    "pelic_key = pelic[mask1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PELIC texts with key lemmas: 7223\n",
      "Total PELIC texts: 46239\n",
      "Percentage of PELIC texts with key lemmas: 15.62\n"
     ]
    }
   ],
   "source": [
    "# Checking how many texts include a key lemma\n",
    "print('PELIC texts with key lemmas:',len(pelic_key))\n",
    "print('Total PELIC texts:',len(pelic))\n",
    "print('Percentage of PELIC texts with key lemmas:',round(len(pelic_key)/len(pelic)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of key lemmas used in PELIC: 26\n",
      "Number of key lemmas NOT used in PELIC: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking number of key lemmas in/not in PELIC\n",
    "peliclemmas_list = pelic.lems_corrected.tolist() #make a list of all lemmas in PELIC\n",
    "peliclemmas_list = [x for y in peliclemmas_list for x in y] #flatten the list\n",
    "in_pelic = [x for x in key_lemma_list if x in peliclemmas_list]\n",
    "not_in_pelic = [x for x in key_lemma_list if x not in peliclemmas_list]\n",
    "\n",
    "print('Number of key lemmas used in PELIC:',len(in_pelic))\n",
    "print('Number of key lemmas NOT used in PELIC:',len(not_in_pelic))\n",
    "\n",
    "# Students used all of the 27 key lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key family forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a list of the key family forms\n",
    "key_family_forms_list = {x for y in coca_key.form_POS.tolist() for x in y} # made into a list and flattened\n",
    "len(key_family_forms_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to change the POS tags in PELIC 'toks_pos_corrected' to match the COCA tags (easier than the reverse)\n",
    "\n",
    "# First simplify by reducing two two characters\n",
    "pelic.toks_pos_corrected = pelic.toks_pos_corrected.apply(lambda x: [(i[0],i[1][0:2]) for i in x])\n",
    "quick_POS_dict = {'JJ':'jj','NN':'nn','RB':'rr', 'VB':'vv'}\n",
    "\n",
    "# Then replace the ones being analyzed and lower case the words (ignoring all others for now)\n",
    "pelic['toks_pos_corrected'] = pelic.toks_pos_corrected.apply\\\n",
    "(lambda x: [(i[0].lower(),quick_POS_dict[i[1]]) if i[1] in quick_POS_dict else i for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8715"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how many texts include a key lemma\n",
    "mask2 = pelic.toks_pos_corrected.apply(lambda x: any(item for item in key_family_forms_list if item in x))\n",
    "pelic_key_forms = pelic[mask2]\n",
    "len(pelic_key_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Next, checking total number of instances when one of these forms used (not just number of texts)\n",
    "\n",
    "# Creating a column in pelic_key_forms with the forms used from coca_key.lemma_POS\n",
    "pelic_key_forms['forms_in_text'] = pelic_key_forms['toks_pos_corrected'].apply(lambda x: [i for i in x if i in key_family_forms_list])\n",
    "\n",
    "# Creating a column with the number of the forms found in the above column\n",
    "pelic_key_forms['len_forms'] = [len(x) for x in pelic_key_forms['forms_in_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15811"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of occurrences of key family forms\n",
    "pelic_key_forms['len_forms'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Narrowing dataset\n",
    "- For valid natural production, we will include only want written free written production, i.e. from writing classes and not reading or grammar classes where students might have copied the word.\n",
    "- Only the first versions of texts will be included to avoid duplicates and corrections made due to teacher feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New number of texts: 7570\n",
      "New number of tokens: 13658\n"
     ]
    }
   ],
   "source": [
    "# Keeping only version 1 of texts\n",
    "pelic_key_forms = pelic_key_forms.loc[pelic_key_forms.version == 1]\n",
    "print('New number of texts:',len(pelic_key_forms))\n",
    "print('New number of tokens:',pelic_key_forms['len_forms'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New number of texts: 3775\n",
      "New number of tokens: 8326\n"
     ]
    }
   ],
   "source": [
    "# Keeping only writing texts (class code 'w')\n",
    "pelic_key_forms = pelic_key_forms.loc[pelic_key_forms.class_code == 'w']\n",
    "print('New number of texts:',len(pelic_key_forms))\n",
    "print('New number of tokens:',pelic_key_forms['len_forms'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the version and class_code columns which are no longer relevant\n",
    "pelic_key_forms = pelic_key_forms.drop(['class_code','version'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling the dataframe for later use\n",
    "pelic_key_forms.to_pickle(\"pelic_key_forms.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>text</th>\n",
       "      <th>level_id</th>\n",
       "      <th>native_language</th>\n",
       "      <th>gender</th>\n",
       "      <th>toks_nltk</th>\n",
       "      <th>toks_pos</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>errors_in_text</th>\n",
       "      <th>len_errors_in_text</th>\n",
       "      <th>toks_corrected</th>\n",
       "      <th>lem_errors</th>\n",
       "      <th>len_lem_errors</th>\n",
       "      <th>lems_corrected</th>\n",
       "      <th>toks_pos_errors</th>\n",
       "      <th>len_toks_pos_errors</th>\n",
       "      <th>toks_pos_corrected</th>\n",
       "      <th>forms_in_text</th>\n",
       "      <th>len_forms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>dk5</td>\n",
       "      <td>In my country we usually don't use tea bags. F...</td>\n",
       "      <td>4</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Female</td>\n",
       "      <td>[In, my, country, we, usually, do, n't, use, t...</td>\n",
       "      <td>[(In, IN), (my, PRP$), (country, NN), (we, PRP...</td>\n",
       "      <td>[in, my, country, we, usually, do, n't, use, t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[In, my, country, we, usually, do, n't, use, t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[in, my, country, we, usually, do, n't, use, t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[(In, IN), (my, PR), (country, nn), (we, PR), ...</td>\n",
       "      <td>[(heat, nn)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>gc5</td>\n",
       "      <td>Last week I planned to go paintball match' but...</td>\n",
       "      <td>4</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>Male</td>\n",
       "      <td>[Last, week, I, planned, to, go, paintball, ma...</td>\n",
       "      <td>[(Last, JJ), (week, NN), (I, PRP), (planned, V...</td>\n",
       "      <td>[last, week, i, plan, to, go, paintball, match...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[Last, week, I, planned, to, go, paintball, ma...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[last, week, i, plan, to, go, paintball, match...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[(last, jj), (week, nn), (I, PR), (planned, vv...</td>\n",
       "      <td>[(accepted, vv)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>er4</td>\n",
       "      <td>when you want to enjoy drinking a tea you have...</td>\n",
       "      <td>4</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Male</td>\n",
       "      <td>[when, you, want, to, enjoy, drinking, a, tea,...</td>\n",
       "      <td>[(when, WRB), (you, PRP), (want, VBP), (to, TO...</td>\n",
       "      <td>[when, you, want, to, enjoy, drink, a, tea, yo...</td>\n",
       "      <td>[coract, finaly]</td>\n",
       "      <td>2</td>\n",
       "      <td>[when, you, want, to, enjoy, drinking, a, tea,...</td>\n",
       "      <td>[coract, finaly]</td>\n",
       "      <td>2</td>\n",
       "      <td>[when, you, want, to, enjoy, drink, a, tea, yo...</td>\n",
       "      <td>[(coract, JJ), (finaly, NN)]</td>\n",
       "      <td>2</td>\n",
       "      <td>[(when, WR), (you, PR), (want, vv), (to, TO), ...</td>\n",
       "      <td>[(correct, jj)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>ea3</td>\n",
       "      <td>Here are a few instructions for typing in Engl...</td>\n",
       "      <td>4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Male</td>\n",
       "      <td>[Here, are, a, few, instructions, for, typing,...</td>\n",
       "      <td>[(Here, RB), (are, VBP), (a, DT), (few, JJ), (...</td>\n",
       "      <td>[here, be, a, few, instruction, for, type, in,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[Here, are, a, few, instructions, for, typing,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[here, be, a, few, instruction, for, type, in,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[(here, rr), (are, vv), (a, DT), (few, jj), (i...</td>\n",
       "      <td>[(open, vv), (select, vv)]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>cz7</td>\n",
       "      <td>Every one like a special kind of food. For me ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Male</td>\n",
       "      <td>[Every, one, like, a, special, kind, of, food,...</td>\n",
       "      <td>[(Every, DT), (one, CD), (like, IN), (a, DT), ...</td>\n",
       "      <td>[every, one, like, a, special, kind, of, food,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[Every, one, like, a, special, kind, of, food,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[every, one, like, a, special, kind, of, food,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[(Every, DT), (one, CD), (like, IN), (a, DT), ...</td>\n",
       "      <td>[(special, jj), (specially, rr)]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          anon_id                                               text  \\\n",
       "answer_id                                                              \n",
       "3             dk5  In my country we usually don't use tea bags. F...   \n",
       "25            gc5  Last week I planned to go paintball match' but...   \n",
       "30            er4  when you want to enjoy drinking a tea you have...   \n",
       "97            ea3  Here are a few instructions for typing in Engl...   \n",
       "111           cz7  Every one like a special kind of food. For me ...   \n",
       "\n",
       "           level_id native_language  gender  \\\n",
       "answer_id                                     \n",
       "3                 4         Turkish  Female   \n",
       "25                4         Turkish    Male   \n",
       "30                4          Arabic    Male   \n",
       "97                4          Korean    Male   \n",
       "111               4          Arabic    Male   \n",
       "\n",
       "                                                   toks_nltk  \\\n",
       "answer_id                                                      \n",
       "3          [In, my, country, we, usually, do, n't, use, t...   \n",
       "25         [Last, week, I, planned, to, go, paintball, ma...   \n",
       "30         [when, you, want, to, enjoy, drinking, a, tea,...   \n",
       "97         [Here, are, a, few, instructions, for, typing,...   \n",
       "111        [Every, one, like, a, special, kind, of, food,...   \n",
       "\n",
       "                                                    toks_pos  \\\n",
       "answer_id                                                      \n",
       "3          [(In, IN), (my, PRP$), (country, NN), (we, PRP...   \n",
       "25         [(Last, JJ), (week, NN), (I, PRP), (planned, V...   \n",
       "30         [(when, WRB), (you, PRP), (want, VBP), (to, TO...   \n",
       "97         [(Here, RB), (are, VBP), (a, DT), (few, JJ), (...   \n",
       "111        [(Every, DT), (one, CD), (like, IN), (a, DT), ...   \n",
       "\n",
       "                                                      lemmas  \\\n",
       "answer_id                                                      \n",
       "3          [in, my, country, we, usually, do, n't, use, t...   \n",
       "25         [last, week, i, plan, to, go, paintball, match...   \n",
       "30         [when, you, want, to, enjoy, drink, a, tea, yo...   \n",
       "97         [here, be, a, few, instruction, for, type, in,...   \n",
       "111        [every, one, like, a, special, kind, of, food,...   \n",
       "\n",
       "             errors_in_text  len_errors_in_text  \\\n",
       "answer_id                                         \n",
       "3                        []                   0   \n",
       "25                       []                   0   \n",
       "30         [coract, finaly]                   2   \n",
       "97                       []                   0   \n",
       "111                      []                   0   \n",
       "\n",
       "                                              toks_corrected  \\\n",
       "answer_id                                                      \n",
       "3          [In, my, country, we, usually, do, n't, use, t...   \n",
       "25         [Last, week, I, planned, to, go, paintball, ma...   \n",
       "30         [when, you, want, to, enjoy, drinking, a, tea,...   \n",
       "97         [Here, are, a, few, instructions, for, typing,...   \n",
       "111        [Every, one, like, a, special, kind, of, food,...   \n",
       "\n",
       "                 lem_errors  len_lem_errors  \\\n",
       "answer_id                                     \n",
       "3                        []               0   \n",
       "25                       []               0   \n",
       "30         [coract, finaly]               2   \n",
       "97                       []               0   \n",
       "111                      []               0   \n",
       "\n",
       "                                              lems_corrected  \\\n",
       "answer_id                                                      \n",
       "3          [in, my, country, we, usually, do, n't, use, t...   \n",
       "25         [last, week, i, plan, to, go, paintball, match...   \n",
       "30         [when, you, want, to, enjoy, drink, a, tea, yo...   \n",
       "97         [here, be, a, few, instruction, for, type, in,...   \n",
       "111        [every, one, like, a, special, kind, of, food,...   \n",
       "\n",
       "                        toks_pos_errors  len_toks_pos_errors  \\\n",
       "answer_id                                                      \n",
       "3                                    []                    0   \n",
       "25                                   []                    0   \n",
       "30         [(coract, JJ), (finaly, NN)]                    2   \n",
       "97                                   []                    0   \n",
       "111                                  []                    0   \n",
       "\n",
       "                                          toks_pos_corrected  \\\n",
       "answer_id                                                      \n",
       "3          [(In, IN), (my, PR), (country, nn), (we, PR), ...   \n",
       "25         [(last, jj), (week, nn), (I, PR), (planned, vv...   \n",
       "30         [(when, WR), (you, PR), (want, vv), (to, TO), ...   \n",
       "97         [(here, rr), (are, vv), (a, DT), (few, jj), (i...   \n",
       "111        [(Every, DT), (one, CD), (like, IN), (a, DT), ...   \n",
       "\n",
       "                              forms_in_text  len_forms  \n",
       "answer_id                                               \n",
       "3                              [(heat, nn)]          1  \n",
       "25                         [(accepted, vv)]          1  \n",
       "30                          [(correct, jj)]          1  \n",
       "97               [(open, vv), (select, vv)]          2  \n",
       "111        [(special, jj), (specially, rr)]          2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pelic_key_forms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next notebook: 3_Concordances.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
